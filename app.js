// /exam-trainer/app.js
// 문제집 2세트(1회·2회) 38문항 데이터 + 풀이 로직

const examSets = {
  set1: {
    id: "set1",
    name: "실전 문제집 1",
    tag: "1회",
    questions: [
      {
        id: 1,
        stem: "다음 중 기계학습에 대한 설명으로 가장 적절한 것은?",
        options: [
          "사람이 모든 규칙을 미리 코딩하고 컴퓨터는 그대로 실행하는 방식이다.",
          "데이터(경험)를 바탕으로 시스템의 구조나 매개변수를 조정해 성능을 높이는 기술이다.",
          "데이터 없이도 순수한 논리 규칙만으로 지능을 구현하는 기술이다.",
          "하드웨어 성능을 높여 프로그램 속도를 개선하는 방법이다."
        ],
        correctIndex: 1,
        explanation: "기계학습은 경험(데이터)을 통해 파라미터/구조를 바꾸며 성능을 향상시키는 방법입니다."
      },
      {
        id: 2,
        stem: "다음 중 연역적 추론에 해당하는 예는?",
        options: [
          "여러 도시의 기온 데이터를 보고 “지구 온난화가 진행 중”이라고 가정한다.",
          "기존 이론을 바탕으로 특정 실험 결과를 미리 예측한다.",
          "고객 구매 패턴 데이터를 보고 새로운 마케팅 전략 규칙을 뽑는다.",
          "이미지 데이터를 통해 고양이/개 분류기를 학습시킨다."
        ],
        correctIndex: 1,
        explanation: "일반적인 법칙(이론)에서 개별 사례(실험 결과)를 예측하는 것이 연역입니다."
      },
      {
        id: 3,
        stem: "다음 중 기계학습 기본 단계의 올바른 순서로 가장 적절한 것은?",
        options: [
          "평가 → 모델 학습 → 데이터 정제 → 예측",
          "학습 데이터 수집 → 데이터 정제 → 모델 학습 → 평가 → 예측",
          "예측 → 학습 데이터 수집 → 모델 학습 → 평가",
          "모델 학습 → 데이터 정제 → 평가 → 예측"
        ],
        correctIndex: 1,
        explanation: "일반적으로 수집 → 정제 → 학습 → 평가 → 예측 순서로 진행합니다."
      },
      {
        id: 4,
        stem: "다음 중 가중치와 편향에 대한 설명으로 옳지 않은 것은?",
        options: [
          "가중치는 입력이 출력에 미치는 중요도를 조절한다.",
          "편향은 모든 입력이 0일 때의 기본 출력 수준을 결정한다.",
          "가중치와 편향은 학습 과정에서 업데이트되는 매개변수다.",
          "편향은 입력 데이터에서 직접 계산되는 값으로, 학습 대상이 아니다."
        ],
        correctIndex: 3,
        explanation: "편향도 가중치와 마찬가지로 학습 과정에서 조정되는 파라미터입니다."
      },
      {
        id: 5,
        stem: "다음 중 과적합(overfitting)을 유발하기 쉬운 상황은?",
        options: [
          "데이터는 많고 모델은 단순하다.",
          "데이터는 적고 모델이 매우 복잡하다.",
          "데이터와 모델 복잡도가 잘 맞는다.",
          "학습을 매우 짧게만 수행한다."
        ],
        correctIndex: 1,
        explanation: "적은 데이터 + 복잡한 모델은 훈련 데이터에만 맞춘 과적합 위험이 큽니다."
      },
      {
        id: 6,
        stem: "다음 중 과적합을 줄이기 위한 방법으로 보기 어려운 것은?",
        options: [
          "모델을 더 단순하게 만든다.",
          "validation 성능이 최고일 때 학습을 조기 종료한다.",
          "데이터 증강을 통해 데이터 다양성을 높인다.",
          "학습 시간을 최대한 길게 늘려 훈련 오류를 0에 가깝게 만든다."
        ],
        correctIndex: 3,
        explanation: "훈련 오류를 지나치게 줄이면 보통 과적합이 심해집니다."
      },
      {
        id: 7,
        stem: "다음 중 과소적합(underfitting)을 가장 잘 설명한 것은?",
        options: [
          "훈련 데이터에서는 잘 맞지만 테스트 데이터에서만 성능이 떨어진다.",
          "모델이 지나치게 복잡하여 노이즈까지 학습한다.",
          "모델이 너무 단순하거나 학습이 부족해 훈련 데이터조차 잘 맞추지 못한다.",
          "데이터가 너무 많아 학습이 수렴하지 않는다."
        ],
        correctIndex: 2,
        explanation: "패턴 자체를 충분히 학습하지 못한 상태가 과소적합입니다."
      },
      {
        id: 8,
        stem: "편향(bias)-분산(variance) 관점에서 옳지 않은 설명은?",
        options: [
          "편향이 크면 모델의 기본 가정이 실제 데이터와 많이 다르다.",
          "분산이 크면 데이터가 조금만 바뀌어도 예측이 크게 달라진다.",
          "이상적인 모델은 편향과 분산이 모두 가능한 한 낮다.",
          "편향을 줄이면 항상 분산도 자동으로 줄어든다."
        ],
        correctIndex: 3,
        explanation: "편향을 줄이면 오히려 분산이 커질 수 있어 둘 사이 trade-off가 있습니다."
      },
      {
        id: 9,
        stem: "다음 중 지도 학습(supervised)과 비지도 학습(unsupervised)의 비교가 옳은 것은?",
        options: [
          "지도 학습은 정답 레이블이 없고, 비지도 학습은 항상 레이블이 있다.",
          "지도 학습은 입력→출력 관계를 학습하고, 비지도 학습은 데이터 구조/군집을 찾는다.",
          "둘 다 정답 레이블 없이 군집만 찾는다.",
          "둘 다 항상 회귀 문제에만 사용된다."
        ],
        correctIndex: 1,
        explanation: "지도=레이블로 입력→출력 매핑 학습, 비지도=레이블 없이 구조/패턴 추출이 핵심입니다."
      },
      {
        id: 10,
        stem: "다음 중 회귀(regression) 문제에 해당하는 것은?",
        options: [
          "이메일을 스팸/정상으로 분류",
          "하루 평균 기온을 예측",
          "손글씨 숫자를 0~9로 분류",
          "뉴스 기사를 카테고리로 분류"
        ],
        correctIndex: 1,
        explanation: "연속값(기온)을 예측하는 것이 회귀 문제입니다."
      },
      {
        id: 11,
        stem: "단순 선형 회귀에서 모델 f(x)=Wx+b 에 대한 설명으로 옳지 않은 것은?",
        options: [
          "W는 기울기, b는 절편이다.",
          "W와 b는 손실 함수를 최소화하는 값으로 학습된다.",
          "선형 회귀는 입력과 출력 관계가 직선으로 근사 가능한 경우에 적합하다.",
          "선형 회귀는 항상 곡선 형태만 표현하고 직선은 표현할 수 없다."
        ],
        correctIndex: 3,
        explanation: "선형 회귀는 기본적으로 직선 관계를 표현하는 모델입니다."
      },
      {
        id: 12,
        stem: "평균 제곱 오차(MSE)를 사용하는 이유로 가장 적절한 것은?",
        options: [
          "오차의 부호를 살리기 위해",
          "오차가 클수록 더 큰 페널티를 주기 위해",
          "절댓값보다 계산이 복잡해 학습을 어렵게 하기 위해",
          "분류 문제에서 정확도를 바로 구하기 위해"
        ],
        correctIndex: 1,
        explanation: "오차를 제곱하면 큰 오차를 더 강하게 벌점 줄 수 있고, 양·음 오차 상쇄도 줄어듭니다."
      },
      {
        id: 13,
        stem: "최소 제곱법(Least Squares)의 한계로 옳은 것은?",
        options: [
          "손실 함수를 정의하지 않는다.",
          "차원이 커질수록 역행렬 계산 등으로 계산 비용이 크게 증가한다.",
          "비선형 모델에만 적용 가능하다.",
          "확률적 경사 하강법보다 항상 빠르다."
        ],
        correctIndex: 1,
        explanation: "고차원일수록 행렬 연산 비용이 커지는 것이 최소 제곱법의 약점입니다."
      },
      {
        id: 14,
        stem: "다음 중 경사 하강법(Gradient Descent)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "손실 함수의 기울기를 이용해 파라미터를 반복적으로 업데이트한다.",
          "손실을 줄이기 위해 기울기의 반대 방향으로 이동한다.",
          "학습률이 너무 크면 발산할 수 있다.",
          "기울기의 방향과 같은 쪽으로 이동해야 손실이 줄어든다."
        ],
        correctIndex: 3,
        explanation: "손실을 줄이려면 기울기의 반대 방향으로 움직여야 합니다."
      },
      {
        id: 15,
        stem: "에폭(epoch)을 가장 정확히 설명한 것은?",
        options: [
          "손실 함수 값이 0이 되는 시점",
          "전체 훈련 데이터를 한 번 모두 사용하여 파라미터를 업데이트한 횟수",
          "배치 크기와 동일한 값",
          "학습률의 또 다른 이름"
        ],
        correctIndex: 1,
        explanation: "에폭은 전체 데이터셋을 한 번 모두 보고 학습한 주기 수를 의미합니다."
      },
      {
        id: 16,
        stem: "의사결정 트리에 대한 설명으로 옳지 않은 것은?",
        options: [
          "질문(특징+임계값)을 통해 데이터를 분할해 나가는 모델이다.",
          "결정 노드는 데이터 분할을 수행하고, 리프 노드는 최종 예측을 담당한다.",
          "분할 기준을 통해 불순도를 낮추는 방향으로 트리를 성장시킨다.",
          "항상 연속형 특징만 다룰 수 있고, 범주형 특징은 사용할 수 없다."
        ],
        correctIndex: 3,
        explanation: "트리는 연속형·범주형 모두 사용할 수 있는 모델입니다."
      },
      {
        id: 17,
        stem: "다음 중 불순도(impurity)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "노드 내 데이터가 한 클래스일수록 불순도가 크다.",
          "여러 클래스가 골고루 섞여 있을수록 불순도가 크다.",
          "불순도가 낮을수록 클래스 혼합 정도가 심하다.",
          "불순도는 트리 학습과 무관한 값이다."
        ],
        correctIndex: 1,
        explanation: "불순도는 얼마나 섞여 있는지를 나타내며 균등 혼합일수록 값이 큽니다."
      },
      {
        id: 18,
        stem: "다음 중 모델 평가 지표에 대한 설명으로 옳지 않은 것은?",
        options: [
          "정확도는 전체 중 맞춘 비율로, 클래스 불균형에서는 오해를 줄 수 있다.",
          "민감도는 실제 양성 중에서 양성으로 잘 맞춘 비율이다.",
          "특이도는 실제 음성 중에서 음성으로 잘 맞춘 비율이다.",
          "정밀도는 실제 양성 전체 중에서 양성으로 예측한 비율이다."
        ],
        correctIndex: 3,
        explanation: "정밀도는 ‘양성으로 예측한 것 중’ 실제 양성 비율입니다."
      },
      {
        id: 19,
        stem: "다음 중 퍼셉트론의 한계를 가장 잘 설명한 것은?",
        options: [
          "선형 분리 문제를 해결할 수 없다.",
          "XOR처럼 선형 분리 불가능한 문제를 하나의 퍼셉트론으로는 해결할 수 없다.",
          "가중치를 학습할 수 없다.",
          "활성화 함수를 사용할 수 없다."
        ],
        correctIndex: 1,
        explanation: "단층 퍼셉트론은 하나의 직선으로만 나눌 수 있어 XOR 같은 문제는 풀지 못합니다."
      },
      {
        id: 20,
        stem: "다음 중 활성화 함수에 대한 설명으로 옳지 않은 것은?",
        options: [
          "입력×가중치 합에 비선형 함수를 적용해 복잡한 패턴을 학습한다.",
          "Sigmoid, Tanh, ReLU 등이 대표적인 예이다.",
          "활성화 함수가 없으면 여러 층을 쌓아도 전체는 하나의 선형 변환이 된다.",
          "활성화 함수를 쓰면 항상 기울기 소멸 문제가 완전히 사라진다."
        ],
        correctIndex: 3,
        explanation: "비선형 함수가 필요하지만, Sigmoid처럼 오히려 기울기 소멸을 유발하는 함수도 있습니다."
      },
      {
        id: 21,
        stem: "다음 중 다층 퍼셉트론(MLP)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "은닉층이 없는 단층 신경망이다.",
          "입력층–은닉층(들)–출력층으로 구성되며, 각 층 사이에 비선형 활성화 함수를 사용한다.",
          "항상 한 개의 은닉층만 가질 수 있다.",
          "선형 회귀와 완전히 동일한 구조다."
        ],
        correctIndex: 1,
        explanation: "MLP는 여러 은닉층과 비선형 활성화를 통해 복잡한 함수를 근사합니다."
      },
      {
        id: 22,
        stem: "다음 중 역전파(backpropagation) 알고리즘의 핵심 아이디어를 가장 잘 표현한 것은?",
        options: [
          "출력층에서 계산된 오차를 입력층 방향으로 전파하며 각 가중치에 대한 오차 기여도를 계산해 업데이트한다.",
          "항상 무작위 방향으로 가중치를 변경해 지역 최적해를 탈출한다.",
          "입력층에서 출력층 방향으로만 기울기를 계산한다.",
          "은닉층 가중치는 고정하고 출력층 가중치만 업데이트한다."
        ],
        correctIndex: 0,
        explanation: "역전파는 오차를 역방향으로 전파하며 체인 룰로 각 가중치의 미분을 구합니다."
      },
      {
        id: 23,
        stem: "다음 식에서 ∂E/∂w_ij = (∂E/∂o_j)·(∂o_j/∂net_j)·(∂net_j/∂w_ij) 세 항을 올바르게 해석한 것은?",
        options: [
          "(오차 영향) × (활성화 함수 영향) × (입력에 대한 가중치 직접 영향)",
          "(입력 영향) × (오차 영향) × (활성화 함수 영향)",
          "(활성화 함수 영향) × (가중치 영향) × (정답 레이블)",
          "(정답) × (예측) × (가중치)"
        ],
        correctIndex: 0,
        explanation: "강의에서 오차 영향, 활성화 미분, 입력·가중치 미분 세 부분으로 분해해 설명합니다."
      },
      {
        id: 24,
        stem: "역전파에서 은닉층 가중치를 업데이트하기 위해 반드시 필요한 정보가 아닌 것은?",
        options: [
          "상위 레이어에서 전달된 오차 신호",
          "해당 노드의 출력 값",
          "해당 노드로 들어오는 입력 값",
          "테스트 데이터의 손실 값"
        ],
        correctIndex: 3,
        explanation: "가중치 업데이트는 훈련 데이터와 해당 레이어의 값들로 계산하며, 테스트 손실은 사용하지 않습니다."
      },
      {
        id: 25,
        stem: "다층 퍼셉트론의 학습 특성에 대한 설명으로 옳지 않은 것은?",
        options: [
          "순방향 전파로 출력을 계산한다.",
          "손실 함수를 통해 출력과 정답의 차이를 구한다.",
          "역전파로 모든 층의 가중치를 갱신한다.",
          "출력층 가중치만 학습하고 은닉층 가중치는 항상 고정한다."
        ],
        correctIndex: 3,
        explanation: "은닉층 가중치도 역전파로 함께 학습됩니다."
      },
      {
        id: 26,
        stem: "다층 퍼셉트론(MLP)의 표현력에 대한 설명으로 가장 적절한 것은?",
        options: [
          "퍼셉트론 여러 개를 조합하더라도 여전히 선형 모델과 동일하다.",
          "여러 선형 분류기(평면)와 비선형 함수를 조합해 복잡한 비선형 경계를 표현할 수 있다.",
          "은닉층이 늘어날수록 항상 표현력이 감소한다.",
          "선형 회귀보다 표현력이 낮다."
        ],
        correctIndex: 1,
        explanation: "다양한 가중치 평면 + 활성화 함수로 복잡한 결정 경계를 만들 수 있습니다."
      },
      {
        id: 27,
        stem: "심층신경망(Deep Neural Network)에 대한 설명으로 옳은 것은?",
        options: [
          "은닉층이 하나만 있는 신경망이다.",
          "다층 퍼셉트론에서 은닉층 개수를 늘려 깊은 네트워크를 구성한 것이다.",
          "반드시 순환 구조(RNN)를 포함해야 한다.",
          "항상 선형 활성화 함수만 사용해야 한다."
        ],
        correctIndex: 1,
        explanation: "딥러닝은 기본적으로 깊은 MLP 구조를 의미합니다."
      },
      {
        id: 28,
        stem: "다음 중 그래디언트 소멸(vanishing gradient)의 주된 원인이 아닌 것은?",
        options: [
          "시그모이드 함수처럼 대부분 구간에서 도함수가 작은 활성화 함수 사용",
          "네트워크 깊이가 매우 깊어짐",
          "입력/출력 분산을 고려하지 않은 부적절한 가중치 초기화",
          "ReLU 계열 활성화 함수 사용"
        ],
        correctIndex: 3,
        explanation: "ReLU는 오히려 그래디언트 소멸을 완화하기 위해 도입된 대표 비선형 함수입니다."
      },
      {
        id: 29,
        stem: "다음 중 L1 규제와 L2 규제 비교로 옳은 것은?",
        options: [
          "L1은 가중치 제곱합, L2는 절댓값 합을 페널티로 쓴다.",
          "L1은 일부 가중치를 0으로 만들어 특징 선택 효과가 있고, L2는 모든 가중치를 점진적으로 작게 만든다.",
          "두 규제 모두 가중치 값을 크게 만드는 역할을 한다.",
          "규제는 과적합을 심화시키는 역할을 한다."
        ],
        correctIndex: 1,
        explanation: "L1은 sparse 해지고, L2는 전반적으로 가중치를 작게 만드는 경향이 있습니다."
      },
      {
        id: 30,
        stem: "다음 중 드롭아웃(dropout)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "학습 시 일부 노드를 무작위로 끄는 방식이다.",
          "매번 다른 서브 네트워크를 학습하는 효과가 있어 과적합을 줄이는 데 도움이 된다.",
          "테스트(추론) 시에도 학습 때처럼 동일 비율로 노드를 끄는 것이 일반적이다.",
          "테스트 시 모든 노드를 사용하는 대신, 학습 시의 드롭 비율을 반영해 가중치나 출력을 스케일링하는 방식으로 사용된다."
        ],
        correctIndex: 2,
        explanation: "드롭아웃은 학습 시에만 일부 노드를 끄고, 테스트 시에는 전체 네트워크를 사용합니다."
      },
      {
        id: 31,
        stem: "다음 중 데이터 증강(data augmentation)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "학습 속도를 높이기 위해 훈련 샘플 수를 줄이는 기법이다.",
          "원본 데이터를 여러 번 복사해 단순히 데이터 개수만 늘리는 기법이다.",
          "원본 데이터에 회전·이동·노이즈 등 변형을 가해 새로운 샘플을 생성함으로써 일반화 성능을 높이는 기법이다.",
          "테스트 데이터에만 적용하여 모델의 예측을 바꾸는 기법이다."
        ],
        correctIndex: 2,
        explanation: "의미 있는 변형을 통해 데이터 다양성을 높여 과적합을 줄이고 일반화를 향상시킵니다."
      },
      {
        id: 32,
        stem: "다음 중 Q-러닝(Q-learning)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "MDP에서 최적 정책을 찾기 위한 model-free 강화학습 알고리즘이다.",
          "Q-테이블의 각 셀에는 특정 상태-행동 쌍의 Q값이 저장된다.",
          "Q-러닝은 예상했던 값(Q)과 실제로 경험한 결과(target)의 차이를 조금씩 수정하며 학습한다.",
          "환경의 전이 확률과 보상 함수를 정확히 알고 있어야만 사용할 수 있는 알고리즘이다."
        ],
        correctIndex: 3,
        explanation: "Q-러닝은 환경 모델을 몰라도 경험을 통해 Q값을 학습하는 model-free 방법입니다."
      },
      {
        id: 33,
        stem: "다음 중 one-hot encoding의 특징으로 옳지 않은 것은?",
        options: [
          "각 단어를 단어 사전 크기만큼의 벡터로 나타낸다.",
          "서로 다른 단어 벡터는 항상 서로 직교한다.",
          "단어 간 의미적 유사도를 거리로 자연스럽게 표현할 수 있다.",
          "단어 사전이 커질수록 차원이 매우 커진다."
        ],
        correctIndex: 2,
        explanation: "one-hot 벡터는 유사도 정보를 담지 못해 의미적 관계를 표현하기 어렵습니다."
      },
      {
        id: 34,
        stem: "다음 중 Word2Vec 임베딩에 대한 설명으로 가장 적절한 것은?",
        options: [
          "단어의 출현 빈도만을 사용해 임의의 점에 배치한다.",
          "비슷한 문맥에서 등장하는 단어들이 임베딩 공간에서 서로 가깝도록 학습한다.",
          "문장 단위 분류를 위해서만 설계된 모델이다.",
          "단어 의미 대신 단어 길이 정보를 벡터에 저장한다."
        ],
        correctIndex: 1,
        explanation: "Word2Vec은 비슷한 문맥 단어가 임베딩 공간에서 가깝게 위치하도록 학습합니다."
      },
      {
        id: 35,
        stem: "다음 중 Transformer의 Self-Attention에 대한 설명으로 옳지 않은 것은?",
        options: [
          "각 단어를 Query, Key, Value 벡터로 변환해 단어들 사이의 연관도를 계산한다.",
          "모든 단어 쌍에 대해 attention score를 계산한다.",
          "어떤 단어에 주목할지(가중치)를 학습해 문맥 속 의미를 파악한다.",
          "항상 바로 이전 단어 한 개에만 attention을 줄 수 있다."
        ],
        correctIndex: 3,
        explanation: "Self-Attention은 문장 전체의 모든 단어에 대해 가중치를 줄 수 있습니다."
      },
      {
        id: 36,
        stem: "다음 중 BERT와 GPT의 구조 비교로 옳은 것은?",
        options: [
          "둘 다 Encoder만 사용하는 양방향 모델이다.",
          "둘 다 Decoder만 사용하는 단방향 모델이다.",
          "BERT는 Encoder-only, GPT는 Decoder-only 구조를 사용한다.",
          "BERT는 RNN, GPT는 CNN 기반이다."
        ],
        correctIndex: 2,
        explanation: "BERT는 Encoder-only 양방향, GPT는 Decoder-only autoregressive 구조입니다."
      },
      {
        id: 37,
        stem: "다음 중 Decoder의 Masked Self-Attention 목적을 가장 잘 설명한 것은?",
        options: [
          "미래 단어까지 모두 보게 해 정확도를 높이기 위해",
          "계산량을 줄이기 위해 항상 한 단어만 보도록 하기 위해",
          "현재 시점 이후의 단어를 보지 못하게 막아, 지금까지 생성된 단어만으로 다음 단어를 예측하게 하기 위해",
          "Encoder와 구조를 완전히 동일하게 만들기 위해"
        ],
        correctIndex: 2,
        explanation: "언어 생성에서는 미래 정보를 숨기고 과거 정보만으로 다음 토큰을 예측해야 합니다."
      },
      {
        id: 38,
        stem: "다음 중 Instruction tuning에 대한 설명으로 가장 적절한 것은?",
        options: [
          "사전 학습 전, 임의의 잡음 데이터를 이용해 모델을 초기화하는 과정이다.",
          "다음 단어 예측 과제만을 대규모 텍스트로 학습하는 단계이다.",
          "사람이 작성하거나 정제한 질문–정답 형식의 데이터로 모델을 추가 학습시켜, 지시를 잘 따르도록 만드는 단계이다.",
          "모델의 파라미터를 모두 고정한 채, 새로운 단어 사전만 학습시키는 단계이다."
        ],
        correctIndex: 2,
        explanation: "Pre-training 후 Q&A·명령→응답 데이터를 추가 학습해 지시 수행 능력을 높입니다."
      }
    ]
  },
  set2: {
    id: "set2",
    name: "실전 문제집 2",
    tag: "2회",
    questions: [
      {
        id: 1,
        stem: "다음 중 기계학습의 핵심 아이디어를 가장 잘 나타낸 것은?",
        options: [
          "사람이 모든 규칙을 프로그래밍하고 컴퓨터는 그대로 실행한다.",
          "프로그램이 실행 중 스스로 새로운 하드웨어를 설계한다.",
          "경험 데이터로부터 패턴을 추론하여 이후 비슷한 상황에서 더 잘 수행하도록 파라미터를 바꾼다.",
          "인터넷에서 규칙을 검색해 자동으로 복사한다."
        ],
        correctIndex: 2,
        explanation: "경험(E)로부터 시스템 구조/파라미터를 바꾸어 성능을 향상시키는 것이 기계학습입니다."
      },
      {
        id: 2,
        stem: "다음 중 귀납적 추론에 해당하는 예시는?",
        options: [
          "“모든 사람은 죽는다” → “소크라테스는 사람이다” → “소크라테스는 죽는다”",
          "여러 실험 데이터를 보고 “온도와 압력 사이에 이러한 법칙이 있다”고 일반식을 세운다.",
          "우주론 이론을 바탕으로 특정 별의 위치를 예측한다.",
          "공리 체계로부터 정리를 증명한다."
        ],
        correctIndex: 1,
        explanation: "개별 사례(데이터)에서 일반적인 법칙·패턴을 뽑아내는 것이 귀납입니다."
      },
      {
        id: 3,
        stem: "다음 중 기계학습 기본 단계에 속하지 않는 것은?",
        options: [
          "학습 데이터 수집",
          "학습 데이터 정제 및 전처리",
          "모델 학습 및 평가",
          "배포 후 사용자의 기기 사양 업그레이드"
        ],
        correctIndex: 3,
        explanation: "기기 사양 업그레이드는 ML 파이프라인 바깥의 이슈입니다."
      },
      {
        id: 4,
        stem: "다음 중 특징 수(d)가 커질 때 일반적으로 나타나는 현상으로 옳지 않은 것은?",
        options: [
          "학습해야 할 매개변수 수가 늘어난다.",
          "필요한 학습 데이터 양도 함께 증가하는 경향이 있다.",
          "너무 크면 차원의 저주로 학습이 어려워질 수 있다.",
          "d가 커질수록 항상 과적합 위험이 줄어든다."
        ],
        correctIndex: 3,
        explanation: "차원이 커질수록 보통 과적합 위험이 커집니다."
      },
      {
        id: 5,
        stem: "다항(고차) 모델에 대한 설명으로 옳은 것은?",
        options: [
          "차수가 높을수록 항상 좋은 일반화 성능을 보장한다.",
          "차수가 높을수록 복잡한 관계를 표현할 수 있지만, 변수·계산량이 크게 늘어난다.",
          "1차 다항 모델은 선형 모델이 아니다.",
          "고차 다항 모델은 작은 데이터셋에서는 학습이 불가능하다."
        ],
        correctIndex: 1,
        explanation: "표현력은 늘지만 파라미터 수·계산량·과적합 위험도 함께 증가합니다."
      },
      {
        id: 6,
        stem: "훈련 오차는 거의 0이지만, 검증 오차가 매우 큰 경우 가장 가능성이 높은 상황은?",
        options: [
          "데이터 누락으로 인한 과소적합",
          "모델이 너무 단순해서 아무 것도 못 배운 상태",
          "모델이 훈련 데이터에 과도하게 특화된 과적합",
          "학습률이 0에 가까운 경우"
        ],
        correctIndex: 2,
        explanation: "훈련만 잘 맞고 검증이 나쁘면 전형적인 과적합 패턴입니다."
      },
      {
        id: 7,
        stem: "다음 중 과소적합(underfitting) 발생 가능성이 가장 큰 설정은?",
        options: [
          "특징이 풍부한데 매우 간단한 선형 모델 사용",
          "훈련 데이터 수가 적고 복잡한 심층 신경망 사용",
          "학습 epoch 수가 매우 많음",
          "데이터 증강과 규제를 모두 강하게 사용"
        ],
        correctIndex: 0,
        explanation: "데이터 패턴이 복잡한데 모델이 지나치게 단순하면 underfitting이 됩니다."
      },
      {
        id: 8,
        stem: "다음 중 편향–분산 관점에서 과적합과 더 관련 깊은 쪽은?",
        options: [
          "높은 편향, 낮은 분산",
          "낮은 편향, 높은 분산",
          "편향과 분산 모두 매우 큼",
          "편향·분산과 무관하다."
        ],
        correctIndex: 1,
        explanation: "과적합은 보통 bias는 낮지만 variance가 큰 경우로 볼 수 있습니다."
      },
      {
        id: 9,
        stem: "다음 중 비지도 학습(Unsupervised Learning)의 대표적인 예로 가장 적절한 것은?",
        options: [
          "주택 가격 예측",
          "이미지의 개/고양이 분류",
          "고객 데이터를 비슷한 집단으로 묶는 군집화",
          "이메일 스팸 여부 판별"
        ],
        correctIndex: 2,
        explanation: "군집화는 레이블 없이 데이터 구조를 파악하는 전형적인 비지도 학습 문제입니다."
      },
      {
        id: 10,
        stem: "다음 중 지도 학습의 대표적인 문제 유형이 아닌 것은?",
        options: [
          "회귀",
          "분류",
          "군집화",
          "이진 분류"
        ],
        correctIndex: 2,
        explanation: "군집화는 비지도 학습에 속합니다."
      },
      {
        id: 11,
        stem: "다음 중 선형 회귀에 대한 설명으로 옳지 않은 것은?",
        options: [
          "입력과 출력 사이 관계를 직선으로 근사한다.",
          "파라미터 W, b는 손실을 최소화하는 값으로 학습된다.",
          "학습 데이터와 회귀선의 거리를 줄이는 것이 목표다.",
          "선형 회귀는 분류 문제에서만 사용된다."
        ],
        correctIndex: 3,
        explanation: "선형 회귀는 연속값 예측(회귀)에 사용되는 모델입니다."
      },
      {
        id: 12,
        stem: "다음 중 손실 함수(평균 제곱 오차)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "예측값과 정답의 차이를 더해 부호 있는 값으로 남긴다.",
          "오차 제곱을 평균 내므로, 큰 오차에 대해 더 강한 페널티를 준다.",
          "항상 0 또는 1의 값만 가진다.",
          "분류 정확도와 항상 동일한 값이다."
        ],
        correctIndex: 1,
        explanation: "제곱은 큰 오차를 더 크게 벌주고, 양·음 오차 상쇄도 줄입니다."
      },
      {
        id: 13,
        stem: "경사 하강법에서 학습률(learning rate)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "너무 크면 최솟값을 지나치며 발산할 수 있다.",
          "너무 작으면 수렴까지 시간이 오래 걸릴 수 있다.",
          "손실 값이 항상 감소하도록 자동으로 조절된다.",
          "파라미터를 한 번에 얼마나 이동시킬지 결정하는 값이다."
        ],
        correctIndex: 2,
        explanation: "기본 GD에서는 사용자가 설정하는 하이퍼파라미터이며 자동 조절되지 않습니다."
      },
      {
        id: 14,
        stem: "다음 중 SGD / 배치 / 미니배치 설명의 짝으로 올바른 것은?",
        options: [
          "SGD: 전체 데이터 한 번에, 배치: 샘플 하나씩, 미니배치: 일부 샘플씩",
          "SGD: 샘플 하나씩, 배치: 전체 데이터 한 번에, 미니배치: 일부 샘플 묶음씩",
          "SGD: 샘플 하나씩, 배치: 일부 샘플씩, 미니배치: 전체 데이터 한 번에",
          "셋 다 동일한 방법이다."
        ],
        correctIndex: 1,
        explanation: "온라인(SGD)–배치–미니배치 순으로 구분됩니다."
      },
      {
        id: 15,
        stem: "의사결정 트리가 분할할 때 사용하는 기준에 대한 설명으로 가장 적절한 것은?",
        options: [
          "항상 임의로 특징을 선택한다.",
          "정보 이득이 최대가 되도록, 즉 자식 노드의 불순도가 최대가 되도록 한다.",
          "정보 이득이 최대가 되도록, 즉 자식 노드의 가중 평균 불순도가 최소가 되도록 한다.",
          "불순도와 무관하게 가장 값이 큰 특징부터 분할한다."
        ],
        correctIndex: 2,
        explanation: "정보 이득 = 부모 불순도 − 자식 가중 불순도이므로 이를 최대화하는 분할을 택합니다."
      },
      {
        id: 16,
        stem: "다음 중 지니 계수와 엔트로피 비교 설명으로 옳지 않은 것은?",
        options: [
          "둘 다 값이 작을수록 노드가 “깨끗하다(순수하다)”는 뜻이다.",
          "엔트로피는 지니보다 기울기가 가파라 클래스 불균형에 더 민감하다.",
          "지니는 계산이 단순해 속도 면에서 유리하다.",
          "지니 계수는 클래스 수가 늘어날수록 항상 0에 수렴한다."
        ],
        correctIndex: 3,
        explanation: "지니 계수는 클래스 수가 많아지면 1에 가까운 값으로 단조 증가합니다."
      },
      {
        id: 17,
        stem: "다음 중 의사결정 트리의 한계로 옳은 것은?",
        options: [
          "항상 선형 모델보다 일반화 성능이 좋다.",
          "작은 데이터 변화에도 트리 구조가 크게 바뀔 수 있다.",
          "비선형 경계를 학습할 수 없다.",
          "고차원 데이터에서 오히려 과적합이 줄어든다."
        ],
        correctIndex: 1,
        explanation: "트리는 데이터 변화에 민감해 분산이 크고, 고차원·복잡한 경계에 약합니다."
      },
      {
        id: 18,
        stem: "암 진단 모델에서 환자를 놓치는 것(FN)이 매우 큰 문제라고 할 때, 가장 중요한 평가지표는?",
        options: [
          "정확도(Accuracy)",
          "민감도(Recall, TPR)",
          "정밀도(Precision)",
          "특이도(Specificity)"
        ],
        correctIndex: 1,
        explanation: "실제 양성 중 놓치지 않고 잡아내는 비율인 민감도가 중요합니다."
      },
      {
        id: 19,
        stem: "다음 중 퍼셉트론에 대한 설명으로 옳지 않은 것은?",
        options: [
          "입력에 가중치를 곱해 합한 뒤 활성화 함수를 통과시켜 출력한다.",
          "단층 퍼셉트론은 XOR과 같은 선형 분리 불가능 문제를 해결하지 못한다.",
          "퍼셉트론 여러 개를 조합해 다층 퍼셉트론을 구성할 수 있다.",
          "퍼셉트론은 활성화 함수 없이도 비선형 문제를 학습할 수 있다."
        ],
        correctIndex: 3,
        explanation: "활성화 함수가 없으면 선형 결합만 가능해 비선형 문제를 학습할 수 없습니다."
      },
      {
        id: 20,
        stem: "다음 중 활성화 함수 사용 목적에 대한 설명으로 가장 적절한 것은?",
        options: [
          "가중치를 자동으로 초기화하기 위해",
          "네트워크가 비선형 관계를 표현할 수 있도록 하기 위해",
          "입력 데이터를 정규화하기 위해",
          "항상 출력이 0 또는 1이 되게 하기 위해"
        ],
        correctIndex: 1,
        explanation: "비선형 활성화 덕분에 선형을 넘어서는 복잡한 패턴을 표현할 수 있습니다."
      },
      {
        id: 21,
        stem: "다음 중 Sigmoid 활성화 함수의 특성으로 옳지 않은 것은?",
        options: [
          "출력이 0과 1 사이로 제한된다.",
          "입력이 0 근처에서 기울기가 가장 크다.",
          "입력 절댓값이 커질수록 기울기가 0에 가까워진다.",
          "기울기가 항상 1이어서 그래디언트 소멸을 막아 준다."
        ],
        correctIndex: 3,
        explanation: "Sigmoid는 끝단에서 기울기가 거의 0이라 오히려 그래디언트 소멸을 일으킬 수 있습니다."
      },
      {
        id: 22,
        stem: "다층 퍼셉트론의 학습 순서를 올바르게 나열한 것은? (가: 손실 계산, 나: 순방향 전파, 다: 역전파)",
        options: [
          "가 → 나 → 다",
          "나 → 가 → 다",
          "나 → 다 → 가",
          "다 → 가 → 나"
        ],
        correctIndex: 1,
        explanation: "forward(나) → loss 계산(가) → backward(다) 순서로 진행됩니다."
      },
      {
        id: 23,
        stem: "다음 중 체인 룰을 이용한 역전파에 대한 설명으로 옳은 것은?",
        options: [
          "출력층에서 입력층까지의 모든 미분을 한 번에 직접 계산한다.",
          "각 층에서 ‘나까지 온 오차’와 ‘내가 출력에 미치는 영향’을 곱해, 가중치별로 오차 기여도를 계산한다.",
          "입력층 가중치만 계산하면 되고, 은닉층은 자동으로 맞춰진다.",
          "체인 룰은 출력층에만 적용된다."
        ],
        correctIndex: 1,
        explanation: "backprop은 dE/do × do/dnet × dnet/dw 구조로 미분을 분해해 전파합니다."
      },
      {
        id: 24,
        stem: "다음 중 은닉층의 가중치를 업데이트할 때 필요한 값이 아닌 것은?",
        options: [
          "상위 층으로부터 전달된 오차(델타)",
          "해당 은닉 노드의 활성화 함수 도함수 값",
          "해당 노드로 들어오는 입력 값(또는 이전 층 출력)",
          "테스트 데이터의 정답 레이블"
        ],
        correctIndex: 3,
        explanation: "가중치 업데이트는 훈련 데이터 기준으로 계산하며, 테스트 정답은 사용하지 않습니다."
      },
      {
        id: 25,
        stem: "다층 퍼셉트론(MLP)에 대한 설명으로 옳은 것은?",
        options: [
          "은닉층이 많아도 활성화 함수가 없으면 전체는 하나의 선형 모델과 같다.",
          "은닉층을 추가하면 항상 과적합이 줄어든다.",
          "은닉층은 입력과 무관한 상수만 출력한다.",
          "MLP는 회귀에는 사용할 수 없고 분류에만 사용된다."
        ],
        correctIndex: 0,
        explanation: "비선형이 없으면 선형 변환들의 합성은 결국 하나의 선형 변환입니다."
      },
      {
        id: 26,
        stem: "다층 퍼셉트론(MLP)에 대한 설명으로 옳은 것은?",
        options: [
          "은닉층이 많아도 활성화 함수가 없으면 전체는 하나의 선형 모델과 같다.",
          "은닉층을 추가하면 항상 표현력이 감소한다.",
          "은닉층은 입력과 무관한 상수만 출력한다.",
          "MLP는 회귀에는 사용할 수 없고 분류에만 사용된다."
        ],
        correctIndex: 0,
        explanation: "비선형이 없으면 여러 층을 쌓아도 전체는 선형 모델 하나와 같습니다."
      },
      {
        id: 27,
        stem: "다음 중 그래디언트 소멸 현상을 가장 잘 설명하는 것은?",
        options: [
          "깊은 네트워크에서 역전파되는 기울기가 앞쪽 레이어로 갈수록 거의 0이 되어 가중치가 잘 업데이트되지 않는 현상",
          "학습률이 커질수록 손실이 급격히 증가하는 현상",
          "기울기가 항상 1로 유지되는 현상",
          "파라미터 개수가 줄어드는 현상"
        ],
        correctIndex: 0,
        explanation: "초기 레이어의 gradient가 0에 가까워져 학습이 거의 안 되는 문제가 vanishing gradient입니다."
      },
      {
        id: 28,
        stem: "다음 중 그래디언트 소멸을 완화하기 위한 방법으로 보기 어려운 것은?",
        options: [
          "ReLU 계열 활성화 함수 사용",
          "Xavier와 같은 적절한 가중치 초기화",
          "교차 엔트로피 + 소프트맥스 손실 사용",
          "네트워크를 불필요하게 더 깊게 쌓기"
        ],
        correctIndex: 3,
        explanation: "네트워크를 깊게만 쌓으면 소멸 문제가 더 심해질 수 있습니다."
      },
      {
        id: 29,
        stem: "다음 중 L1 규제의 특징으로 가장 적절한 것은?",
        options: [
          "손실 함수에 가중치 제곱합을 더해 모든 가중치를 조금씩 작게 만든다.",
          "손실 함수에 가중치 절댓값 합을 더해 일부 가중치를 0으로 만드는 경향이 있다.",
          "규제 계수를 키울수록 가중치 값이 커진다.",
          "과적합을 증가시키기 위해 사용된다."
        ],
        correctIndex: 1,
        explanation: "L1 규제는 스파스(sparse) 해져서 특징 선택 효과가 있습니다."
      },
      {
        id: 30,
        stem: "드롭아웃(dropout)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "학습 시 뉴런 일부를 무작위로 비활성화해 하나의 큰 모델을 많은 서브모델의 앙상블처럼 만든다.",
          "특정 뉴런에 과도하게 의존하는 것을 방지하는 정규화 기법이다.",
          "테스트 단계에서도 학습과 동일하게 뉴런을 랜덤하게 끈다.",
          "테스트 단계에서는 모든 뉴런을 사용하되, 학습 시 드롭 비율을 고려해 스케일링한다."
        ],
        correctIndex: 2,
        explanation: "테스트 때는 전체 네트워크를 사용하고, 학습 시 드롭 비율을 반영해 출력/가중치를 조정합니다."
      },
      {
        id: 31,
        stem: "입력 데이터를 정규화(normalization) 하는 주된 이유로 가장 적절한 것은?",
        options: [
          "모델 파라미터 수를 줄이기 위해",
          "모든 입력 특징이 비슷한 범위를 갖도록 하여 학습을 빠르고 안정적으로 만들기 위해",
          "정답 레이블을 제거하기 위해",
          "과소적합 문제를 강제로 발생시키기 위해"
        ],
        correctIndex: 1,
        explanation: "입력 스케일을 맞추면 각 노드의 최적 파라미터를 더 빨리 찾을 수 있고 학습이 안정적입니다."
      },
      {
        id: 32,
        stem: "다음 중 Q-러닝(Q-learning)의 특징으로 옳지 않은 것은?",
        options: [
          "상태–행동 쌍에 대해 Q값을 학습한다.",
          "환경의 전이확률/보상 모델을 몰라도 사용할 수 있는 model-free 방법이다.",
          "Q-테이블의 행은 상태, 열은 행동을 나타낼 수 있다.",
          "학습 과정에서 보상을 전혀 사용하지 않는다."
        ],
        correctIndex: 3,
        explanation: "Q-러닝은 보상 신호를 사용해 예상 Q와 실제 target Q의 차이를 줄이도록 업데이트합니다."
      },
      {
        id: 33,
        stem: "다음 중 one-hot encoding과 비교했을 때 Word2Vec 임베딩의 장점으로 가장 적절한 것은?",
        options: [
          "단어 사전 크기만큼 차원이 커진다.",
          "단어 간 의미적 관계를 거리/방향으로 표현할 수 있다.",
          "새로운 단어가 나오면 벡터 차원을 늘려야 한다.",
          "모든 단어 벡터가 서로 직교한다."
        ],
        correctIndex: 1,
        explanation: "Word2Vec에서는 비슷한 문맥의 단어들이 가까이 위치해 의미적 유사성을 표현합니다."
      },
      {
        id: 34,
        stem: "다음 중 CBOW와 Skip-gram에 대한 설명으로 옳지 않은 것은?",
        options: [
          "CBOW는 주변 단어들로 중심 단어를 예측한다.",
          "Skip-gram은 중심 단어로 주변 단어들을 예측한다.",
          "둘 다 단어 임베딩을 학습하기 위한 Word2Vec 구조이다.",
          "Skip-gram에서는 중심 단어와 상관없는 단어만을 항상 가깝게 만든다."
        ],
        correctIndex: 3,
        explanation: "Skip-gram은 실제 주변 단어는 가깝게, negative 샘플은 멀어지게 학습합니다."
      },
      {
        id: 35,
        stem: "다음 중 negative sampling을 사용하는 주된 이유로 가장 적절한 것은?",
        options: [
          "모든 단어를 항상 같은 위치로 모으기 위해",
          "Softmax 계산 시 모든 단어에 대해 가중치를 업데이트해야 하는 계산량을 줄이고, 같이 등장하지 않는 단어와는 멀어지도록 하기 위해",
          "단어 사전을 줄이기 위해",
          "RNN의 은닉 상태 크기를 줄이기 위해"
        ],
        correctIndex: 1,
        explanation: "일부 negative 단어만 샘플링해 손실을 계산함으로써 붕괴를 막고 연산량도 줄입니다."
      },
      {
        id: 36,
        stem: "다음 중 Transformer가 RNN 기반 모델에 비해 가지는 장점으로 올바른 것은?",
        options: [
          "항상 한 단어씩 순차적으로 처리해야 하므로 병렬화가 어렵다.",
          "Self-Attention으로 장거리 의존성을 처리하면서, 모든 단어를 동시에 처리할 수 있다.",
          "위치 정보를 사용할 수 없어 문장 순서를 고려하지 못한다.",
          "hidden state를 사용할 수 없다."
        ],
        correctIndex: 1,
        explanation: "Transformer는 Self-Attention+Positional Encoding으로 긴 문맥을 병렬로 처리합니다."
      },
      {
        id: 37,
        stem: "다음 중 BERT와 GPT의 차이를 가장 잘 설명한 것은?",
        options: [
          "BERT는 Decoder-only, GPT는 Encoder-only 구조이다.",
          "BERT는 양방향 Encoder를 사용해 마스크된 토큰을 예측하고, GPT는 Decoder를 사용해 다음 토큰을 예측한다.",
          "둘 다 양방향 Encoder 구조로, 학습 방식이 동일하다.",
          "둘 다 Decoder-only 구조로, 항상 왼쪽에서 오른쪽으로만 본다."
        ],
        correctIndex: 1,
        explanation: "BERT는 Encoder-only 양방향, GPT는 Decoder-only 다음 토큰 예측 구조입니다."
      },
      {
        id: 38,
        stem: "다음 중 Instruction tuning(지시 따르기 튜닝)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "사전 학습된 언어 모델에 대해 추가로 수행되는 파인튜닝의 일종이다.",
          "사람이 정제한 질문–정답/명령–응답 데이터를 사용해, 모델이 자연어 지시를 더 잘 따르도록 학습한다.",
          "“피자를 설명해줘” 같은 질의에 자연스러운 설명을 하도록 만드는 데 기여한다.",
          "사전 학습 단계에서 웹 텍스트만으로 다음 단어 예측을 학습하는 과정을 Instruction tuning이라고 부른다."
        ],
        correctIndex: 3,
        explanation: "4번은 일반적인 pre-training 설명이고, Instruction tuning은 그 이후 지시형 데이터로 추가 학습하는 단계입니다."
      }
    ]
  },
    set3: {
    id: "set3",
    name: "실전 문제집 3",
    tag: "3회",
    questions: [
      {
        id: 1,
        stem: "기계학습에 대한 설명으로 가장 적절한 것은?",
        options: [
          "사람이 모든 규칙을 미리 작성하고, 컴퓨터는 그 규칙을 그대로 실행하는 방식이다.",
          "경험 데이터로부터 패턴을 추론하여, 시스템의 구조나 매개변수를 바꾸면서 성능을 향상시키는 기술이다.",
          "데이터 없이도 전문가의 직관만으로 규칙을 설계하여 사용하는 기술이다.",
          "하드웨어 성능을 높여 알고리즘 속도를 증가시키는 기술이다."
        ],
        correctIndex: 1,
        explanation: "기계학습은 경험(데이터)에 따라 구조·파라미터를 바꾸며 성능을 높이는 기술이다."
      },
      {
        id: 2,
        stem: "다음 중 귀납적 추론의 예시에 해당하는 것은?",
        options: [
          "뉴턴의 법칙에서 출발해 특정 운동 실험 결과를 계산한다.",
          "여러 번의 관측 결과를 바탕으로 온도와 압력 사이에 일정한 관계가 있다고 일반식을 세운다.",
          "우주론 이론을 바탕으로 특정 별의 위치를 예측한다.",
          "공리에서 논리적으로 정리를 증명한다."
        ],
        correctIndex: 1,
        explanation: "개별 사례(데이터)에서 일반 법칙을 뽑아내는 것이 귀납이다."
      },
      {
        id: 3,
        stem: "일반적인 기계학습 기본 단계의 올바른 순서는?",
        options: [
          "예측 → 모델 학습 → 데이터 수집 → 평가",
          "학습 데이터 수집 → 데이터 정제 → 모델 학습 → 평가 → 예측",
          "모델 학습 → 데이터 정제 → 예측 → 평가",
          "데이터 정제 → 예측 → 모델 학습 → 평가"
        ],
        correctIndex: 1,
        explanation: "보통 수집→정제→학습→평가→예측 순서로 진행된다."
      },
      {
        id: 4,
        stem: "다음 중 초매개변수(하이퍼파라미터)에 해당하는 것은?",
        options: [
          "선형 회귀의 가중치 W",
          "신경망의 편향 b",
          "학습률(learning rate)",
          "특정 샘플의 입력 특징 값 x"
        ],
        correctIndex: 2,
        explanation: "학습률·에폭 수 등은 사용자가 미리 정하는 초매개변수이다."
      },
      {
        id: 5,
        stem: "특징 수(d)가 매우 커질 때 일반적으로 나타나는 현상으로 보기 어려운 것은?",
        options: [
          "학습해야 할 매개변수 수가 증가한다.",
          "필요한 학습 데이터 양이 증가하는 경향이 있다.",
          "잘못 설계하면 차원의 저주로 학습이 어려워질 수 있다.",
          "d가 커질수록 자연스럽게 과적합 위험이 줄어든다."
        ],
        correctIndex: 3,
        explanation: "차원이 커질수록 보통 과적합 위험은 커진다."
      },
      {
        id: 6,
        stem: "다항(고차) 모델에 대한 설명으로 가장 적절한 것은?",
        options: [
          "차수가 높아지면 항상 더 좋은 일반화 성능을 보장한다.",
          "차수가 높아질수록 복잡한 관계를 표현할 수 있지만, 매개변수 수와 계산량이 크게 증가한다.",
          "1차 다항 모델은 선형 모델이 아니다.",
          "고차 다항 모델은 작은 데이터셋에서 절대 사용 불가능하다."
        ],
        correctIndex: 1,
        explanation: "표현력은 커지지만 파라미터·연산량·과적합 위험이 함께 커진다."
      },
      {
        id: 7,
        stem: "다음 설명에 해당하는 상태를 고르시오.\n\"훈련 데이터에서는 오류가 거의 0에 가까운데, 새 데이터(검증 데이터)에서는 오류가 매우 크다.\"",
        options: [
          "과소적합",
          "과적합",
          "데이터 누락",
          "차원의 저주"
        ],
        correctIndex: 1,
        explanation: "훈련만 잘 맞고 새로운 데이터에서 성능이 나쁘면 과적합이다."
      },
      {
        id: 8,
        stem: "다음 중 편향(bias)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "데이터가 조금만 바뀌어도 예측 결과가 크게 흔들리는 정도",
          "모델의 기본 가정이 실제 데이터와 얼마나 어긋나는지(체계적인 오차)",
          "모델이 가진 파라미터 수",
          "항상 0으로 만들어야 하는 값"
        ],
        correctIndex: 1,
        explanation: "편향은 모델 가정과 실제 데이터 사이의 체계적인 차이를 뜻한다."
      },
      {
        id: 9,
        stem: "다음 중 비지도 학습의 대표적인 기법과 설명이 잘못 연결된 것은?",
        options: [
          "군집화 – 비슷한 특징을 가진 데이터를 묶는 기법",
          "밀도추정 – 데이터가 따르는 확률 분포를 추정하는 기법",
          "차원축소 – 고차원 데이터를 손실 최소화하며 저차원으로 투영",
          "이상치 탐지 – 레이블이 달린 데이터를 미리 알고, 그에 맞추어 분류"
        ],
        correctIndex: 3,
        explanation: "이상치 탐지는 보통 레이블 없이 이상한 패턴을 찾는 비지도 계열이다."
      },
      {
        id: 10,
        stem: "다음 중 강화 학습에 대한 설명으로 옳은 것은?",
        options: [
          "입력–출력 쌍 레이블을 이용해 지도 학습을 수행한다.",
          "레이블 없이 구조를 찾는 비지도 학습이다.",
          "시행착오와 보상을 통해 최적 정책을 학습한다.",
          "일부 데이터를 가리고 나머지로 예측하는 자기 지도 학습과 동일하다."
        ],
        correctIndex: 2,
        explanation: "강화 학습은 행동–보상–상태 변화를 반복하며 정책을 학습한다."
      },
      {
        id: 11,
        stem: "다음 중 회귀(regression) 문제에 해당하는 것은?",
        options: [
          "손글씨 숫자를 0~9로 분류",
          "뉴스 기사를 정치/경제/스포츠로 분류",
          "집의 면적에 따라 집값(원 단위)을 예측",
          "스팸/정상 이메일 분류"
        ],
        correctIndex: 2,
        explanation: "연속적인 실수 값을 예측하는 문제가 회귀이다."
      },
      {
        id: 12,
        stem: "단순 선형 회귀 모델 y = Wx + b에서 매개변수에 대한 설명으로 옳지 않은 것은?",
        options: [
          "W는 기울기, b는 절편 역할을 한다.",
          "W와 b는 손실 함수를 최소화하도록 학습된다.",
          "W와 b는 모두 학습 데이터에 의존해서 업데이트되는 파라미터다.",
          "b는 사용자가 임의로 정해두고 학습되지 않는다."
        ],
        correctIndex: 3,
        explanation: "b도 W와 마찬가지로 학습 대상 파라미터이다."
      },
      {
        id: 13,
        stem: "평균 제곱 오차(MSE)를 손실 함수로 사용할 때의 장점으로 가장 적절한 것은?",
        options: [
          "오차가 크든 작든 동일한 페널티를 준다.",
          "오차 부호를 그대로 유지한다.",
          "큰 오차에 대해 더 큰 페널티를 줌으로써 큰 실수를 강하게 줄이도록 유도한다.",
          "항상 0과 1 사이의 값만 나온다."
        ],
        correctIndex: 2,
        explanation: "제곱을 취하면 큰 오차일수록 더 큰 벌점을 받는다."
      },
      {
        id: 14,
        stem: "최소 제곱법(Closed-form)으로 선형 회귀 해를 구할 때의 한계로 옳은 것은?",
        options: [
          "손실 함수를 정의하지 않는다.",
          "데이터 차원(d)이 커질수록 역행렬 계산 등으로 계산 비용이 크게 증가한다.",
          "비선형 모델에만 적용할 수 있다.",
          "경사 하강법보다 항상 느리지만, 차원이 커져도 상관없다."
        ],
        correctIndex: 1,
        explanation: "고차원에서 행렬 연산/역행렬 계산 비용이 급격히 증가한다."
      },
      {
        id: 15,
        stem: "경사 하강법(Gradient Descent)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "손실 함수의 기울기(gradient)를 이용해 파라미터를 업데이트한다.",
          "손실을 줄이기 위해 기울기의 반대 방향으로 이동한다.",
          "학습률이 너무 크면 발산할 수 있다.",
          "손실을 줄이기 위해 항상 기울기의 방향과 같은 쪽으로 이동해야 한다."
        ],
        correctIndex: 3,
        explanation: "손실을 줄이려면 기울기의 반대 방향으로 움직인다."
      },
      {
        id: 16,
        stem: "다음 설명 중 학습률(learning rate)과 에폭(epoch)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "학습률은 한 번 업데이트할 때 파라미터를 얼마나 크게 움직일지 결정한다.",
          "학습률이 너무 크면 최솟값 근처를 지나치며 발산할 수 있다.",
          "에폭 수가 너무 적으면 과소적합 가능성이 있다.",
          "에폭 수를 무한히 크게 하면 항상 좋은 일반화 성능을 얻을 수 있다."
        ],
        correctIndex: 3,
        explanation: "에폭이 지나치게 많으면 오히려 과적합이 생길 수 있다."
      },
      {
        id: 17,
        stem: "의사결정 트리에 대한 설명으로 가장 적절한 것은?",
        options: [
          "하나의 직선(혹은 평면)으로만 데이터를 분리하는 선형 분류기이다.",
          "질문(특징+임계값)들을 통해 데이터를 재귀적으로 분할해 나가는 계층적 모델이다.",
          "리프 노드는 항상 연속값을 예측하며 분류 문제에는 사용할 수 없다.",
          "범주형 특징은 사용할 수 없고 연속형 특징만 사용 가능하다."
        ],
        correctIndex: 1,
        explanation: "트리는 질문을 이용해 데이터를 분할하는 계층 구조 모델이다."
      },
      {
        id: 18,
        stem: "의사결정 트리가 분할 기준을 선택할 때 사용하는 개념을 올바르게 설명한 것은?",
        options: [
          "부모 노드의 불순도가 최대가 되도록 분할한다.",
          "자식 노드들의 가중 평균 불순도가 최대가 되도록 분할한다.",
          "부모 불순도 – 자식 가중 평균 불순도(정보 이득)가 최대가 되도록 분할한다.",
          "항상 임의의 특징을 선택하여 공평하게 분할한다."
        ],
        correctIndex: 2,
        explanation: "정보 이득을 최대화하도록 분할 기준을 고른다."
      },
      {
        id: 19,
        stem: "다음 중 지니 계수 vs 엔트로피 비교 설명으로 옳지 않은 것은?",
        options: [
          "둘 다 값이 작을수록 노드가 깨끗하다(순수하다)는 의미이다.",
          "엔트로피는 지니 계수보다 기울기가 가파라 클래스 불균형에 더 민감하다.",
          "지니 계수는 계산이 단순하여 속도 면에서 유리하다.",
          "지니 계수는 클래스 수가 늘어날수록 항상 0에 수렴한다."
        ],
        correctIndex: 3,
        explanation: "클래스 수가 늘어나면 지니 계수는 1에 가까운 값으로 증가한다."
      },
      {
        id: 20,
        stem: "이진 분류에서 정밀도(precision)를 가장 정확히 나타낸 식은?",
        options: [
          "TP / (TP + FN)",
          "TP / (TP + FP)",
          "(TP + TN) / (TP + TN + FP + FN)",
          "TN / (TN + FP)"
        ],
        correctIndex: 1,
        explanation: "정밀도 = 양성으로 예측한 것 중 실제 양성 비율."
      },
      {
        id: 21,
        stem: "퍼셉트론(perceptron)에 대한 설명 중 옳지 않은 것은?",
        options: [
          "생물학적 뉴런을 단순화한 모델로 볼 수 있다.",
          "입력에 가중치를 곱해 합한 뒤 활성화 함수를 통과시켜 출력한다.",
          "단층 퍼셉트론은 XOR과 같은 선형 분리 불가능 문제를 해결하지 못한다.",
          "퍼셉트론 여러 개를 쌓으면 선형이 아닌 XOR도 단층으로 표현할 수 있다."
        ],
        correctIndex: 3,
        explanation: "XOR을 풀려면 다층 구조와 비선형 활성화가 필요하다."
      },
      {
        id: 22,
        stem: "활성화 함수(activation function)를 사용하는 이유로 가장 적절한 것은?",
        options: [
          "가중치를 자동으로 초기화하기 위해",
          "네트워크가 비선형 관계를 표현할 수 있도록 하기 위해",
          "입력 데이터를 정규화하기 위해",
          "항상 출력이 0 또는 1이 되게 하기 위해"
        ],
        correctIndex: 1,
        explanation: "비선형 활성화 덕분에 복잡한 패턴을 표현할 수 있다."
      },
      {
        id: 23,
        stem: "Sigmoid 활성화 함수에 대한 설명으로 옳지 않은 것은?",
        options: [
          "출력이 0~1 사이로 제한된다.",
          "입력이 0 근처일 때 기울기가 가장 크다.",
          "입력 절댓값이 매우 크면 기울기가 거의 0이 된다.",
          "기울기가 항상 1이므로 그래디언트 소멸 문제가 없다."
        ],
        correctIndex: 3,
        explanation: "Sigmoid는 양 끝단에서 기울기가 0에 가까워져 소멸 문제를 일으킬 수 있다."
      },
      {
        id: 24,
        stem: "다층 퍼셉트론(MLP)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "입력층과 출력층만 있고 은닉층은 없다.",
          "입력층–여러 개의 은닉층–출력층 구조를 가지며, 각 층 사이에 활성화 함수가 사용된다.",
          "은닉층은 항상 선형 함수만 사용한다.",
          "회귀 문제에는 사용할 수 없고 분류에만 사용된다."
        ],
        correctIndex: 1,
        explanation: "MLP는 여러 은닉층 + 비선형 활성화로 복잡한 함수를 근사한다."
      },
      {
        id: 25,
        stem: "역전파(backpropagation) 알고리즘의 핵심 아이디어를 가장 잘 설명한 것은?",
        options: [
          "출력층에서 입력층까지 한 번에 기울기를 직접 계산한다.",
          "출력층에서 계산한 오차를 층별로 역방향으로 보내면서, 체인 룰을 이용해 각 가중치가 오차에 기여한 정도를 계산·업데이트한다.",
          "입력층 가중치만 업데이트하고 나머지 가중치는 고정한다.",
          "항상 오차가 0이 될 때까지 반복 없이 한 번만 수행된다."
        ],
        correctIndex: 1,
        explanation: "오차를 뒤로 전파하며 각 가중치의 기여도를 체인 룰로 계산한다."
      },
      {
        id: 26,
        stem: "다음 식에서 세 항의 의미를 올바르게 해석한 것은?\n∂E/∂w_ij = (∂E/∂o_j)·(∂o_j/∂net_j)·(∂net_j/∂w_ij)",
        options: [
          "오차 영향 × 활성화 함수 영향 × 입력·가중치 관계",
          "정답 라벨 × 가중치 영향 × 입력 영향",
          "입력 영향 × 오차 영향 × 활성화 영향",
          "손실 값 × 가중치 값 × 편향 값"
        ],
        correctIndex: 0,
        explanation: "오차 영향, 활성화 미분, 입력×가중치 미분 세 항으로 나눈다."
      },
      {
        id: 27,
        stem: "심층 신경망에서 그래디언트 소멸(vanishing gradient) 문제를 가장 잘 설명한 것은?",
        options: [
          "깊은 네트워크에서 역전파되는 기울기가 항상 1로 유지되는 현상",
          "매우 깊은 구조에서 시그모이드 같은 활성화의 도함수가 작아져, 앞단 레이어로 갈수록 기울기가 거의 0이 되는 현상",
          "학습률이 너무 커서 손실이 급격히 증가하는 현상",
          "파라미터 개수가 줄어드는 현상"
        ],
        correctIndex: 1,
        explanation: "깊고 Sigmoid 계열일수록 앞단으로 가며 gradient가 거의 사라진다."
      },
      {
        id: 28,
        stem: "다음 중 그래디언트 소멸 완화를 위해 제안된 방법으로 보기 어려운 것은?",
        options: [
          "ReLU 계열 활성화 함수를 사용하는 것",
          "입력/출력 분산을 맞추는 Xavier 초기화",
          "교차 엔트로피 + 소프트맥스 조합 사용",
          "층을 무한히 많이 쌓아 깊이를 최대한 늘리는 것"
        ],
        correctIndex: 3,
        explanation: "불필요하게 깊이만 늘리면 오히려 소멸 문제가 심해진다."
      },
      {
        id: 29,
        stem: "분류 문제에서 교차 엔트로피 손실 + 소프트맥스 조합을 많이 사용하는 이유로 가장 적절한 것은?",
        options: [
          "항상 제곱 오차보다 계산량이 적다.",
          "출력이 확률 분포(합=1)가 되며, 정답 분포와의 거리를 자연스럽게 측정할 수 있기 때문이다.",
          "회귀 문제에만 사용할 수 있기 때문이다.",
          "가중치를 업데이트할 필요가 없기 때문이다."
        ],
        correctIndex: 1,
        explanation: "소프트맥스는 확률, 교차 엔트로피는 두 확률 분포 간 차이를 측정한다."
      },
      {
        id: 30,
        stem: "다음 중 미니배치(mini-batch) 학습에 대한 설명으로 옳은 것은?",
        options: [
          "항상 전체 데이터(Full batch)를 한 번에 사용해 업데이트한다.",
          "샘플 한 개만 사용해 업데이트하는 온라인 학습과 동일하다.",
          "여러 샘플을 묶은 작은 배치를 사용해, SGD와 배치의 장점을 적절히 섞은 방식이다.",
          "보통 테스트 데이터에만 사용한다."
        ],
        correctIndex: 2,
        explanation: "1 < batch size < 전체 데이터인 중간 규모 배치를 사용한다."
      },
      {
        id: 31,
        stem: "다음 중 L1 규제 vs L2 규제 비교 설명으로 옳지 않은 것은?",
        options: [
          "L1 규제는 가중치 절댓값 합을 손실에 더해, 일부 가중치를 0으로 만드는 경향이 있다.",
          "L2 규제는 가중치 제곱합을 손실에 더해, 모든 가중치를 조금씩 작게 만든다.",
          "두 규제 모두 과적합을 줄이는 데 도움이 될 수 있다.",
          "L1 규제는 항상 모든 가중치를 동일한 값으로 만든다."
        ],
        correctIndex: 3,
        explanation: "L1은 오히려 일부 가중치를 완전히 0으로 보내 희소성을 만든다."
      },
      {
        id: 32,
        stem: "다음 중 드롭아웃(dropout)에 대한 설명으로 옳지 않은 것은?",
        options: [
          "학습 시 일부 뉴런을 무작위로 비활성화해, 여러 서브 네트워크를 학습하는 효과를 낸다.",
          "특정 뉴런에 과도하게 의존하는 것을 막아 과적합을 줄이는 데 도움된다.",
          "테스트 시에도 학습과 동일하게 뉴런을 랜덤하게 끈다.",
          "테스트 시에는 모든 뉴런을 사용하되, 학습 시 드롭 비율을 고려해 스케일링한다."
        ],
        correctIndex: 2,
        explanation: "드롭아웃은 학습 시에만 적용하고, 테스트 때는 전체 네트워크를 사용한다."
      },
      {
        id: 33,
        stem: "Q-러닝(Q-learning)에 대한 설명으로 가장 적절한 것은?",
        options: [
          "환경의 전이 확률과 보상 함수를 정확히 알고 있어야만 사용할 수 있다.",
          "상태–행동 쌍에 대한 Q값을 학습하며, 환경 모델을 몰라도 되는 model-free 강화학습이다.",
          "보상 정보를 사용하지 않고 무작위 탐색만 수행한다.",
          "Q-테이블의 각 셀에는 항상 실제 보상 r만 저장된다."
        ],
        correctIndex: 1,
        explanation: "Q-러닝은 Q(s,a)를 경험으로 업데이트하는 model-free 방법이다."
      },
      {
        id: 34,
        stem: "다음 중 one-hot encoding의 한계로 가장 적절한 것은?",
        options: [
          "단어 간 의미적 관계(유사도)를 벡터 공간에서 표현하기 어렵다.",
          "모든 단어 벡터가 서로 비슷한 값을 갖는다.",
          "차원이 항상 3 이하로 제한된다.",
          "새로운 단어가 생겨도 벡터 차원을 늘릴 필요가 없다."
        ],
        correctIndex: 0,
        explanation: "one-hot은 서로 직교하는 벡터라 의미/관계 정보를 담기 어렵다."
      },
      {
        id: 35,
        stem: "Word2Vec의 CBOW와 Skip-gram에 대한 설명으로 옳지 않은 것은?",
        options: [
          "CBOW는 주변 단어들로 중심 단어를 예측한다.",
          "Skip-gram은 중심 단어로 주변 단어들을 예측한다.",
          "두 방식 모두 단어 임베딩 벡터를 학습하기 위한 구조이다.",
          "Skip-gram은 중심 단어와 상관없는 단어만 항상 가깝게 만든다."
        ],
        correctIndex: 3,
        explanation: "Skip-gram은 실제 주변 단어는 가깝게, negative 샘플은 멀어지게 학습한다."
      },
      {
        id: 36,
        stem: "Word2Vec에서 negative sampling을 사용하는 주된 이유로 가장 적절한 것은?",
        options: [
          "모든 단어 벡터를 한 점으로 붕괴시키기 위해",
          "Softmax에서 사전의 모든 단어에 대해 계산해야 하는 부담을 줄이고, 같이 등장하지 않는 단어는 멀어지도록 학습하기 위해",
          "단어 사전을 줄이기 위해",
          "RNN의 hidden state 크기를 줄이기 위해"
        ],
        correctIndex: 1,
        explanation: "일부 negative만 샘플링해 계산량을 줄이고 멀어져야 할 단어도 학습한다."
      },
      {
        id: 37,
        stem: "다음 중 Transformer가 RNN 기반 언어 모델에 비해 가지는 장점으로 가장 적절한 것은?",
        options: [
          "항상 단어를 한 개씩 순차적으로 처리해야 하므로 병렬화가 어렵다.",
          "Self-Attention을 통해 문장 전체 단어 간 관계를 한 번에 계산할 수 있어, 긴 의존성을 잘 다루고 병렬 처리가 쉽다.",
          "위치 정보를 전혀 사용할 수 없다.",
          "hidden state를 사용할 수 없어 문맥을 표현할 수 없다."
        ],
        correctIndex: 1,
        explanation: "Transformer는 Self-Attention + Positional Encoding으로 긴 문맥을 병렬 처리한다."
      },
      {
        id: 38,
        stem: "다음 중 BERT / GPT / Instruction tuning 설명으로 올바른 것은?",
        options: [
          "BERT와 GPT 모두 Encoder-only 구조로, 양방향 문맥을 본다.",
          "GPT는 Encoder-only, BERT는 Decoder-only 구조를 사용한다.",
          "BERT는 Encoder-only 양방향 모델, GPT는 Decoder-only 다음 단어 예측 모델이다.",
          "Instruction tuning은 사전 학습 단계에서 웹 텍스트만으로 다음 단어 예측을 학습하는 것을 의미한다."
        ],
        correctIndex: 2,
        explanation: "BERT는 Encoder-only 양방향, GPT는 Decoder-only 구조이며 Instruction tuning은 그 이후 단계다."
      }
    ]
  },
    set4: {
    id: "set4",
    name: "실전 문제집 4",
    tag: "4회",
    questions: [
      {
        id: 1,
        stem: "세 가지 모델 A, B, C에 대해 훈련/검증 오차가 다음과 같다.\n\n- 모델 A: 훈련 오차 = 0.35, 검증 오차 = 0.37\n- 모델 B: 훈련 오차 = 0.05, 검증 오차 = 0.25\n- 모델 C: 훈련 오차 = 0.12, 검증 오차 = 0.14\n\n일반화 성능이 가장 좋을 가능성이 높은 모델은?",
        options: ["A", "B", "C", "세 모델 모두 비슷하다."],
        correctIndex: 2,
        explanation: "훈련/검증 오차 모두 낮고 차이도 작은 모델 C가 가장 적절하다."
      },
      {
        id: 2,
        stem: "모델이 높은 편향(bias)을 가진다는 말과 가장 가까운 설명은?",
        options: [
          "훈련 데이터에 지나치게 맞춰져 과적합된 상태",
          "단순한 가정을 사용해, 다양한 데이터에서도 비슷하게 오차가 나는 상태",
          "데이터가 조금만 바뀌어도 예측이 크게 요동치는 상태",
          "특징 차원이 너무 큰 상태"
        ],
        correctIndex: 1,
        explanation: "높은 편향은 단순한 가정으로 인해 전체적으로 일정한 체계적 오차가 나는 상태다."
      },
      {
        id: 3,
        stem: "특징 차원 d가 커질수록, 일반적으로 요구되는 것은?",
        options: [
          "더 적은 학습 데이터와 더 복잡한 모델",
          "더 많은 학습 데이터와 더 단순한 모델",
          "더 많은 학습 데이터와 적절한 모델 복잡도 조절",
          "데이터 수와 모델 복잡도는 차원과 무관하다"
        ],
        correctIndex: 2,
        explanation: "차원이 커질수록 차원의 저주를 줄이기 위해 데이터 수 증가 + 복잡도 조절이 필요하다."
      },
      {
        id: 4,
        stem: "다음 두 상황 중 과소적합에 더 가까운 것은?\n\n1) 훈련 정확도 99%, 검증 정확도 70%\n2) 훈련 정확도 70%, 검증 정확도 68%\n3) 훈련 정확도 99%, 검증 정확도 98%\n4) 훈련 정확도 50%, 검증 정확도 95%",
        options: ["1)", "2)", "3)", "4)"],
        correctIndex: 1,
        explanation: "훈련/검증 정확도 모두 낮고 비슷하면 데이터 패턴을 충분히 못 배운 과소적합에 가깝다."
      },
      {
        id: 5,
        stem: "다음 중 과적합을 줄이기 위한 전략 조합으로 가장 적절한 것은?",
        options: [
          "모델 복잡도 증가 + 학습 시간 증가",
          "모델 복잡도 감소 + 조기 종료 + 데이터 증강",
          "특징 수 감소 + 학습 데이터 삭제",
          "학습률 증가 + 에폭 무한히 증가"
        ],
        correctIndex: 1,
        explanation: "과적합 완화에는 단순화/조기 종료/데이터 증강 등 일반화 향상 전략이 필요하다."
      },
      {
        id: 6,
        stem: "다음 설명을 읽고 가장 적절한 결론을 고르시오.\n\n모델 D는 오류가 전체적으로 큰 대신, 데이터셋을 여러 번 바꿔도 예측이 크게 변하지 않는다.\n모델 E는 어떤 데이터셋에서는 매우 정확하지만, 다른 데이터셋에서는 성능이 크게 떨어진다.",
        options: [
          "D: 편향↑, 분산↑ / E: 편향↓, 분산↓",
          "D: 편향↑, 분산↓ / E: 편향↓, 분산↑",
          "D: 편향↓, 분산↑ / E: 편향↑, 분산↓",
          "D: 편향↓, 분산↓ / E: 편향↑, 분산↑"
        ],
        correctIndex: 1,
        explanation: "D는 단순하고 일정한 오차(편향↑, 분산↓), E는 데이터에 따라 성능이 크게 변함(편향↓, 분산↑)이다."
      },
      {
        id: 7,
        stem: "다음 중 자기 지도 학습(self-supervised)에 가장 가까운 사례는?",
        options: [
          "사람이 직접 레이블링한 고양이/개 이미지로 분류기 학습",
          "레이블 없이 사용자의 행동 패턴을 군집화",
          "문장 중 일부 단어를 [MASK]로 가리고, 나머지 단어들로 가려진 단어를 예측",
          "에이전트가 보상을 통해 최적 정책을 찾는 게임 플레이"
        ],
        correctIndex: 2,
        explanation: "입력의 일부를 가리고 나머지로 예측하는 방식은 전형적인 자기 지도 학습 형태다."
      },
      {
        id: 8,
        stem: "다음 중 군집화(clustering)를 활용하는 것이 가장 자연스러운 상황은?",
        options: [
          "스팸/정상 이메일 분류",
          "고객들을 몇 개의 유사한 그룹으로 나눠 타겟 마케팅 전략을 세우는 경우",
          "다음 단어를 예측하는 언어 모델",
          "강화 학습에서 행동 가치 함수를 학습하는 경우"
        ],
        correctIndex: 1,
        explanation: "비슷한 고객을 묶어 그룹을 만드는 것은 전형적인 군집화 활용 사례다."
      },
      {
        id: 9,
        stem: "어떤 데이터는 면적이 커질수록 집값이 대체로 증가하는 단조 증가 패턴을 가진다. 이 상황에서 고차 다항 회귀를 사용할 때 가장 주의할 점은?",
        options: [
          "단조 증가 관계이므로 차수가 높을수록 항상 더 적절하다.",
          "차수가 높아지면 데이터가 적을 때 이상한 굴곡이 생겨 과적합될 수 있다.",
          "고차 다항을 쓰면 항상 직선과 같은 결과가 나온다.",
          "차수가 높으면 오히려 편향이 커져서 선형 모델보다 단순해진다."
        ],
        correctIndex: 1,
        explanation: "데이터가 적은데 고차 다항을 쓰면 불필요한 굴곡(진동)으로 과적합이 발생할 수 있다."
      },
      {
        id: 10,
        stem: "단순 선형 모델 ŷ = Wx 에 대해 손실 함수를 L = (Wx - y)^2 로 정의한다. 훈련 데이터가 하나 있고, x=1, y=2, 현재 W=0, 학습률 α=0.5일 때, 한 번의 경사 하강 업데이트 후 W 값은? (∂L/∂W = 2(Wx - y)x)",
        options: ["-2", "-1", "1", "2"],
        correctIndex: 3,
        explanation: "∂L/∂W = 2(0*1 - 2)*1 = -4 → W_new = 0 - 0.5*(-4) = 2."
      },
      {
        id: 11,
        stem: "다음 설명 중 다중 선형 회귀(multiple linear regression)에 해당하는 것은?",
        options: [
          "특징이 하나인 선형 모델로, 2D 좌표평면에서 직선을 학습",
          "여러 개의 특징을 사용해, 고차원 공간에서 하나의 평면(하이퍼플레인)을 학습",
          "선형이 아닌 곡선을 학습하는 모든 모델",
          "회귀가 아닌 분류 문제만을 다루는 트리 모델"
        ],
        correctIndex: 1,
        explanation: "다중 선형 회귀는 여러 특징을 사용해 고차원에서 선형 관계(평면)를 학습한다."
      },
      {
        id: 12,
        stem: "선형 회귀에서 최소 제곱법(Closed-form)과 경사 하강법 비교 중 옳은 것은?",
        options: [
          "최소 제곱법은 고차원에서도 항상 더 빠르고 메모리도 덜 쓴다.",
          "경사 하강법은 데이터가 많고 차원이 클 때 점진적으로 최적해에 접근할 수 있다.",
          "최소 제곱법은 손실 함수를 최소화하지 못한다.",
          "경사 하강법은 손실 함수를 정의하지 않는다."
        ],
        correctIndex: 1,
        explanation: "대용량/고차원일수록 경사 하강법이 현실적인 선택인 경우가 많다."
      },
      {
        id: 13,
        stem: "다음 실험 결과를 보고 가장 적절한 대응은?\n\n현재 모델은 훈련/검증 손실이 모두 줄지만 감소 속도가 매우 느리다. 학습률을 조금 올리면 초반에 빠르게 줄어들지만 이후 발산하는 경향이 있다.",
        options: [
          "학습률을 더 크게 올리고 에폭 수를 줄인다.",
          "학습률을 조금 낮추고, 에폭 수를 늘린다.",
          "학습률 스케줄링(초기에는 크게, 이후에는 작게)을 적용한다.",
          "손실 함수를 제곱오차에서 교차 엔트로피로 바꾼다."
        ],
        correctIndex: 2,
        explanation: "초기에 큰 학습률, 이후 작게 줄이는 스케줄링이 적절한 상황이다."
      },
      {
        id: 14,
        stem: "의사결정 트리를 회귀/분류에 사용할 때의 차이로 옳은 것은?",
        options: [
          "회귀 트리는 리프 노드에 범주형 레이블을 저장한다.",
          "분류 트리는 불순도(지니, 엔트로피), 회귀 트리는 보통 분산/제곱오차를 사용해 분할 기준을 정한다.",
          "분류 트리는 연속형 출력만 가능하다.",
          "회귀 트리는 불순도를 사용하고, 분류 트리는 평균 제곱오차를 사용한다."
        ],
        correctIndex: 1,
        explanation: "분류는 불순도, 회귀는 수치적 오차(분산 등)를 분할 기준으로 사용한다."
      },
      {
        id: 15,
        stem: "어떤 노드에 A/B 두 클래스가 50:50 섞여 있다. 이를 두 자식 노드로 나누는 두 분할 후보가 있다.\n\n① 한쪽 노드 100% A, 다른 노드 100% B\n② 두 노드 모두 A:B = 50:50\n\n지니 계수 관점에서 더 좋은 분할은?",
        options: ["분할 ①", "분할 ②", "두 분할은 동일하다.", "지니 계수와 무관하다."],
        correctIndex: 0,
        explanation: "자식 노드들이 모두 한 클래스만 가지면 지니 계수는 0에 가까워져 가장 좋다."
      },
      {
        id: 16,
        stem: "다음은 이진 분류 모델의 결과이다.\n\n- 실제 양성: 40개 중 30개를 양성으로 맞게 예측, 10개를 음성으로 잘못 예측\n- 실제 음성: 60개 중 50개를 음성으로 맞게 예측, 10개를 양성으로 잘못 예측\n\n이 모델의 재현율(민감도, recall)은?",
        options: ["30 / 40", "30 / 60", "50 / 60", "80 / 100"],
        correctIndex: 0,
        explanation: "재현율 = TP / (TP + FN) = 30 / 40."
      },
      {
        id: 17,
        stem: "희귀 질병 진단에서 전체 환자 중 양성 비율이 1%에 불과하다. 이 상황에서 정확도(accuracy)가 좋은 지표가 아닌 이유로 가장 적절한 것은?",
        options: [
          "항상 0과 1 사이의 값을 갖기 때문이다.",
          "모든 오분류를 동일하게 취급해, 전부 음성이라고 예측해도 정확도가 높게 나올 수 있다.",
          "계산이 너무 복잡하다.",
          "정밀도와 동일한 값을 갖기 때문이다."
        ],
        correctIndex: 1,
        explanation: "극단적 불균형에서는 전부 음성이라고 해도 accuracy가 높게 나올 수 있다."
      },
      {
        id: 18,
        stem: "다음 중 F1-score에 대한 설명으로 옳은 것은?",
        options: [
          "정밀도와 재현율의 산술 평균",
          "정밀도와 재현율의 조화 평균",
          "정확도와 특이도의 기하 평균",
          "항상 정밀도보다 작을 수 없다"
        ],
        correctIndex: 1,
        explanation: "F1 = 2 * (precision * recall) / (precision + recall) 로, 조화 평균이다."
      },
      {
        id: 19,
        stem: "XOR 문제를 학습하기 위해 필요한 조건으로 가장 적절한 것은?",
        options: [
          "단층 퍼셉트론 + 선형 활성화",
          "단층 퍼셉트론 + Sigmoid 활성화",
          "최소 1개 이상의 은닉층 + 비선형 활성화 함수",
          "은닉층 없이 가중치를 매우 크게 설정"
        ],
        correctIndex: 2,
        explanation: "XOR은 선형 분리 불가능 → 은닉층 + 비선형 활성화가 필요하다."
      },
      {
        id: 20,
        stem: "다음 중 ReLU 활성화 함수의 특징으로 옳지 않은 것은?",
        options: [
          "입력이 0보다 크면 기울기가 1이다.",
          "입력이 0 이하인 영역에서는 기울기가 0이다.",
          "매우 큰 양수 영역에서 기울기가 소멸하는 경향이 있다.",
          "깊은 네트워크에서 Sigmoid보다 그래디언트 소멸 문제가 덜하다."
        ],
        correctIndex: 2,
        explanation: "ReLU는 양수 영역에서 기울기 1을 유지해 Sigmoid보다 gradient 소멸에 강하다."
      },
      {
        id: 21,
        stem: "이진 분류 신경망에서 출력 ŷ는 Sigmoid 결과이고, 손실 L = 1/2(ŷ - y)^2를 사용한다. 현재 샘플에서 정답 y=1, 예측 ŷ=0.2라면, 출력층 가중치에 대한 그래디언트 방향은?",
        options: [
          "예측 값을 줄이도록 음의 방향으로",
          "예측 값을 늘리도록 양의 방향으로",
          "변화시키지 않는 0 방향으로",
          "데이터에 따라 임의"
        ],
        correctIndex: 1,
        explanation: "정답보다 예측이 작으므로 출력 값을 키우는 방향(가중치 증가 방향)으로 그래디언트가 나온다."
      },
      {
        id: 22,
        stem: "다음과 같은 네트워크가 있다.\n z = w·x, ŷ = σ(z)(Sigmoid), L = 1/2(ŷ - y)^2.\n현재 x>0, y=0, ŷ≈1일 때 ∂L/∂w의 부호는?",
        options: ["양수", "음수", "0", "데이터와 무관"],
        correctIndex: 0,
        explanation: "ŷ>y이므로 (ŷ - y) > 0, x>0, Sigmoid 미분>0 → 전체 미분 양수, 그래서 w를 줄이는 방향으로 업데이트한다."
      },
      {
        id: 23,
        stem: "역전파에서 이전 은닉층의 가중치를 업데이트하기 위해 꼭 필요한 정보가 아닌 것은?",
        options: [
          "출력층에서 넘어온 오차 기울기(델타)",
          "해당 층의 활성화 함수의 도함수 값",
          "그 층으로 들어오는 입력 값",
          "테스트 데이터의 정답 레이블 전체"
        ],
        correctIndex: 3,
        explanation: "가중치 업데이트는 현재 학습 데이터만 필요하며, 테스트 레이블은 필요 없다."
      },
      {
        id: 24,
        stem: "다층 퍼셉트론(MLP)의 표현력에 대한 설명으로 옳은 것은?",
        options: [
          "은닉층이 1개 이상이고 비선형 활성화를 사용하면, 충분히 많은 뉴런이 있을 때 임의의 연속 함수를 근사할 수 있다.",
          "은닉층이 많을수록 표현력은 줄어든다.",
          "활성화 함수가 선형이더라도 은닉층을 많이 쌓으면 비선형 함수를 표현할 수 있다.",
          "MLP는 회귀 문제에 사용할 수 없다."
        ],
        correctIndex: 0,
        explanation: "보편 근사 정리에 해당하는 내용으로, 은닉층+비선형+충분한 뉴런이면 연속 함수 근사가 가능하다."
      },
      {
        id: 25,
        stem: "아래 중 그래디언트 소멸 문제가 특히 심해질 가능성이 큰 설정은?",
        options: [
          "3층 신경망 + ReLU + Xavier 초기화",
          "50층 신경망 + Sigmoid + 무작위 큰 값으로 초기화",
          "5층 신경망 + ReLU + 적절한 초기화",
          "10층 신경망 + ReLU + 교차 엔트로피 손실"
        ],
        correctIndex: 1,
        explanation: "깊은 네트워크 + Sigmoid + 나쁜 초기값 조합은 gradient 소멸·폭발 위험이 크다."
      },
      {
        id: 26,
        stem: "Xavier 초기화에 대한 설명으로 가장 적절한 것은?",
        options: [
          "모든 가중치를 0으로 초기화해 학습을 안정화한다.",
          "입력과 출력의 분산을 비슷하게 유지하도록 난수를 뽑아 가중치를 초기화한다.",
          "항상 매우 큰 값으로 초기화해 기울기를 크게 만든다.",
          "ReLU에서만 사용 가능하다."
        ],
        correctIndex: 1,
        explanation: "Xavier는 forward/backward에서 분산이 유지되도록 초기 분포를 설계해 gradient 흐름을 안정화한다."
      },
      {
        id: 27,
        stem: "분류 문제에서 교차 엔트로피 손실이 제곱오차보다 선호되는 이유 중 하나로 적절한 것은?",
        options: [
          "항상 계산량이 더 작다.",
          "Softmax와 함께 사용 시, 출력 확률이 정답에 가까워질수록 gradient가 더 정보가 풍부하고 안정적으로 전파되는 경향이 있다.",
          "회귀 문제에도 더 잘 맞기 때문이다.",
          "제곱오차와 완전히 동일한 값을 갖기 때문이다."
        ],
        correctIndex: 1,
        explanation: "Softmax+교차 엔트로피 조합은 분류에서 gradient 특성이 좋아 자주 사용된다."
      },
      {
        id: 28,
        stem: "훈련 과정에서 에폭이 증가함에 따라 훈련 손실은 계속 감소하지만, 검증 손실은 어느 시점 이후 다시 증가하기 시작한다. 이때 가장 적절한 대응은?",
        options: [
          "손실 함수 변경",
          "학습률 증가",
          "그 지점에서 조기 종료하고 해당 파라미터를 최종 모델로 선택",
          "에폭을 더 크게 설정해 충분히 학습"
        ],
        correctIndex: 2,
        explanation: "validation 손실 최소 지점에서 학습을 중단하는 것이 조기 종료의 핵심이다."
      },
      {
        id: 29,
        stem: "다음 설명에 해당하는 가장 적절한 규제는?\n\n모델이 사용하는 특징을 소수만 남기고 나머지 특징들의 가중치는 대부분 0으로 만들고 싶다.",
        options: ["L1 규제", "L2 규제", "드롭아웃", "데이터 증강"],
        correctIndex: 0,
        explanation: "L1은 많은 가중치를 정확히 0으로 보내 희소한(sparse) 모델을 만든다."
      },
      {
        id: 30,
        stem: "드롭아웃이 앙상블 효과를 갖는다고 볼 수 있는 이유는?",
        options: [
          "학습 시 여러 가지 서로 다른 서브 네트워크를 무작위로 학습하고, 테스트 시에는 모든 뉴런을 함께 사용하기 때문이다.",
          "항상 여러 개의 서로 다른 모델 파라미터를 따로 저장하기 때문이다.",
          "트리를 여러 개 학습하는 랜덤 포레스트 구조이기 때문이다.",
          "미니배치를 여러 개 쓰기 때문이다."
        ],
        correctIndex: 0,
        explanation: "각 학습 스텝마다 일부 뉴런을 끄며 다른 서브 네트워크를 학습 → 테스트 시 이들을 동시에 사용하는 효과가 난다."
      },
      {
        id: 31,
        stem: "데이터 증강(Data augmentation)을 적용하는 것이 가장 자연스러운 상황은?",
        options: [
          "수치형 센서 데이터에서 차원을 줄이고 싶을 때",
          "이미지 분류에서 회전/좌우 반전/색상 변화 등으로 데이터 다양성을 늘리고 싶을 때",
          "Q-러닝에서 Q-값을 업데이트할 때",
          "군집화에서 군집 개수를 정할 때"
        ],
        correctIndex: 1,
        explanation: "이미지에 기하/색상 변환을 줘 데이터 다양성을 인위적으로 늘리는 것은 대표적인 증강 사례다."
      },
      {
        id: 32,
        stem: "Q-러닝에서 Q값 업데이트를 개념적으로 가장 잘 설명한 것은?",
        options: [
          "항상 현재 Q값을 0으로 초기화한 뒤, 새로운 보상으로만 덮어쓴다.",
          "예상했던 Q값과 실제로 받은 보상+다음 상태의 최대 Q값 사이의 차이를 조금씩 줄이도록 업데이트한다.",
          "다음 상태는 고려하지 않고 현재 보상만 누적한다.",
          "에피소드가 끝난 뒤 한 번만 업데이트한다."
        ],
        correctIndex: 1,
        explanation: "Q-러닝은 target = r + γ max Q(s',a')와 현재 Q(s,a)의 차이를 점진적으로 줄이는 방식이다."
      },
      {
        id: 33,
        stem: "다음 중 Word2Vec과 같은 임베딩이 one-hot 인코딩에 비해 가지는 장점으로 가장 적절한 것은?",
        options: [
          "항상 더 높은 차원에서 표현하므로 계산량이 줄어든다.",
          "단어 간 유사도를 벡터 공간의 거리/방향으로 표현할 수 있다.",
          "새로운 단어가 생겨도 자동으로 벡터가 생성된다.",
          "단어 순서를 자연스럽게 표현한다."
        ],
        correctIndex: 1,
        explanation: "임베딩은 의미가 비슷한 단어를 가까운 벡터로 표현할 수 있다는 점이 핵심이다."
      },
      {
        id: 34,
        stem: "Skip-gram Word2Vec 모델에서 negative sampling을 사용했을 때, 올바른 설명은?",
        options: [
          "중심 단어와 실제 주변 단어들 간 내적은 작아지도록, negative 샘플과의 내적은 커지도록 학습한다.",
          "중심 단어와 실제 주변 단어들 간 내적은 커지도록, negative 샘플과의 내적은 작아지도록 학습한다.",
          "모든 단어 쌍 내적을 동일하게 0으로 만든다.",
          "one-hot 인코딩을 직접 학습한다."
        ],
        correctIndex: 1,
        explanation: "실제 주변 단어는 가깝게, negative 샘플은 멀어지도록 학습한다."
      },
      {
        id: 35,
        stem: "RNN이 아닌 Transformer를 사용하는 이유로 보기 어려운 것은?",
        options: [
          "Self-Attention을 사용해 긴 문맥 정보도 병렬적으로 처리하기 위해",
          "RNN보다 긴 의존 관계를 학습하는 데 유리하기 때문에",
          "순차 처리가 필요 없어 GPU 병렬화가 쉽기 때문에",
          "언제나 파라미터 수가 RNN보다 적기 때문에"
        ],
        correctIndex: 3,
        explanation: "Transformer가 항상 파라미터가 적은 것은 아니다. 나머지는 대표적인 장점이다."
      },
      {
        id: 36,
        stem: "Transformer에서 Positional Encoding이 필요한 이유는?",
        options: [
          "단어를 one-hot으로 바꾸기 위해",
          "단어의 위치 정보를 주어, 순서를 고려하지 않는 Self-Attention에 어디에 있는 단어인지 정보를 추가하기 위해",
          "모델 파라미터 수를 줄이기 위해",
          "정답 라벨을 인코딩하기 위해"
        ],
        correctIndex: 1,
        explanation: "Self-Attention은 순서를 모르는 구조라 위치 정보를 embedding에 더해 순서를 인코딩해야 한다."
      },
      {
        id: 37,
        stem: "다음 중 BERT와 GPT를 비교한 설명으로 옳은 것은?",
        options: [
          "둘 다 Encoder-only 구조이며, 양방향 문맥을 이용한다.",
          "BERT는 Encoder-only 양방향 모델, GPT는 Decoder-only로 이전 단어들만 보고 다음 단어를 예측한다.",
          "GPT는 Encoder-only, BERT는 Decoder-only 구조이다.",
          "둘 다 Decoder-only 구조이며, 항상 미래 단어를 볼 수 없다."
        ],
        correctIndex: 1,
        explanation: "강의 노트 그대로: BERT=Encoder-only 양방향, GPT=Decoder-only 다음 단어 예측 모델이다."
      },
      {
        id: 38,
        stem: "대규모 언어 모델에 대해 Instruction tuning을 수행하는 주된 목적은?",
        options: [
          "모델이 새로운 단어를 자동으로 사전에 추가하도록",
          "파라미터 수를 줄이기 위해",
          "질문→정답, 지시→응답 형식의 데이터를 추가 학습시켜, 사용자의 지시를 더 잘 따르도록 만들기 위해",
          "항상 번역만 잘 하도록 만들기 위해"
        ],
        correctIndex: 2,
        explanation: "Instruction tuning은 지시를 따르는 능력을 키우는 파인튜닝 단계다."
      }
    ]
  },
    set5: {
    id: "set5",
    name: "실전 문제집 5",
    tag: "5회",
    questions: [
        {
        id: 1,
        stem: "다음 중 “기계학습”에 대한 설명으로 옳지 않은 것은?",
        options: [
            "명시적으로 규칙을 프로그래밍하지 않고, 데이터로부터 패턴을 학습한다.",
            "경험이 쌓일수록 나중에 비슷한 일을 더 잘 처리하도록 파라미터가 바뀐다.",
            "주어진 데이터에 대해 항상 0% 오차를 만드는 모델을 학습하는 것이 핵심 목표이다.",
            "톰 미첼의 정의에는 “경험(E), 과업(T), 성능 측정(P)”가 등장한다."
        ],
        correctIndex: 2,
        explanation: "기계학습의 핵심은 일반화 성능 향상이지, 훈련 데이터 오차 0% 자체가 목표는 아니다."
        },
        {
        id: 2,
        stem: "다음 설명 중 귀납적 추론에 해당하는 것은?",
        options: [
            "물리 법칙을 이용해 새로운 실험의 결과를 계산한다.",
            "여러 실험 데이터를 보고, 이들에 공통된 수학적 관계식을 도출한다.",
            "공리에서 출발해 정리를 논리적으로 증명한다.",
            "이미 알려진 이론을 사용해 특정 현상을 설명한다."
        ],
        correctIndex: 1,
        explanation: "개별 사례에서 일반 법칙을 도출하는 것이 귀납적 추론이다."
        },
        {
        id: 3,
        stem: "모델 복잡도를 x축, 훈련 오차/검증 오차를 y축으로 그렸을 때,\n복잡도가 증가하면서 훈련 오차는 계속 감소하지만 검증 오차는 어느 지점 이후 다시 증가한다.\n이 지점은 어떤 관점에서 해석하는 것이 가장 적절한가?",
        options: [
            "편향이 최소가 되는 지점",
            "분산이 최대가 되는 지점",
            "일반화 오차가 최소가 되어, 모델 복잡도 선택의 “적정점”으로 볼 수 있는 지점",
            "항상 과소적합 구간의 시작점"
        ],
        correctIndex: 2,
        explanation: "검증 오차가 최소인 지점을 일반적으로 최적 복잡도(일반화 오차 최소) 지점으로 본다."
        },
        {
        id: 4,
        stem: "다음 두 실험 결과를 바탕으로 올바른 판단은?\n\n- 모델 M1: 훈련 정확도 0.98, 검증 정확도 0.70\n- 모델 M2: 훈련 정확도 0.85, 검증 정확도 0.84",
        options: [
            "M1은 과소적합, M2는 과적합이다.",
            "M1은 과적합, M2는 비교적 잘 일반화된 상태이다.",
            "두 모델 모두 과소적합이다.",
            "두 모델 모두 과적합이다."
        ],
        correctIndex: 1,
        explanation: "M1은 train–val 차이가 매우 커서 과적합, M2는 둘 다 높고 비슷해 일반화가 좋다."
        },
        {
        id: 5,
        stem: "다음 중 높은 분산(variance)을 가진 모델의 특징으로 가장 적절한 것은?",
        options: [
            "훈련 데이터에 상관없이 항상 일정한 예측을 한다.",
            "데이터셋을 조금만 바꿔도 예측 결과가 크게 달라진다.",
            "이론적으로 매우 단순한 가정만 사용한다.",
            "훈련·검증 오차가 모두 높다."
        ],
        correctIndex: 1,
        explanation: "높은 분산 모델은 데이터에 매우 민감해, 데이터셋이 조금만 바뀌어도 예측이 크게 요동친다."
        },
        {
        id: 6,
        stem: "다음 중 편향–분산 트레이드오프를 고려한 설명으로 옳은 것은?",
        options: [
            "편향을 최소로 만들면 항상 좋은 일반화 성능을 얻는다.",
            "분산을 0으로 만들면 항상 좋은 일반화 성능을 얻는다.",
            "약간의 편향을 허용하더라도 분산을 적절히 낮춰 전체 일반화 오차를 줄이는 전략이 필요하다.",
            "편향과 분산은 서로 독립이므로 따로따로 최소화하면 된다."
        ],
        correctIndex: 2,
        explanation: "편향·분산을 모두 0으로 만들 수는 없고, 전체 일반화 오차 관점에서 균형이 중요하다."
        },
        {
        id: 7,
        stem: "다음 네 가지 상황을 가장 적절한 학습 유형과 연결한 것은?\n\n① 사람의 정답 라벨이 있는 이미지로 고양이/개 분류\n② 사용자 로그를 이용해 숨겨진 사용자 군집 찾기\n③ 게임 환경에서 보상을 받으며 최적 행동 학습\n④ 문장 중 일부 토큰을 가리고 나머지로 예측",
        options: [
            "①지도, ②비지도, ③강화, ④자기지도",
            "①비지도, ②지도, ③강화, ④자기지도",
            "①강화, ②지도, ③비지도, ④자기지도",
            "①자기지도, ②비지도, ③강화, ④지도"
        ],
        correctIndex: 0,
        explanation: "①지도, ②비지도, ③강화, ④자기지도에 각각 해당한다."
        },
        {
        id: 8,
        stem: "다음 설명과 가장 거리가 먼 비지도 학습 기법은?\n\n“고차원 데이터를 저차원으로 투영해 시각화하거나, 중요한 구조만 남기고 압축해서 사용하고 싶다.”",
        options: [
            "PCA 기반 차원 축소",
            "오토인코더 기반 차원 축소",
            "밀도추정을 통한 이상치 탐지",
            "단순 차원축소(dimensionality reduction)"
        ],
        correctIndex: 2,
        explanation: "설명은 차원 축소 목적에 가깝고, 밀도추정 기반 이상치 탐지는 목적이 다르다."
        },
        {
        id: 9,
        stem: "다음 중 “회귀 문제”로 보는 것이 가장 적절한 것은?",
        options: [
            "고객의 월별 이탈 여부(이탈/유지) 예측",
            "뉴스 기사를 정치/경제/스포츠/연예로 분류",
            "사용자의 지속 사용 가능성 점수(0~100 실수) 예측",
            "손글씨 숫자를 0~9 클래스 중 하나로 분류"
        ],
        correctIndex: 2,
        explanation: "연속적인 실수값(0~100)을 예측하므로 회귀 문제에 해당한다."
        },
        {
        id: 10,
        stem: "두 개의 회귀 모델 M1, M2에 대한 평균 제곱 오차(MSE)가 다음과 같다.\n\n- 훈련: M1 = 0.5, M2 = 0.2\n- 검증: M1 = 0.4, M2 = 0.9\n\n일반화 성능 관점에서 더 선호해야 할 모델은?",
        options: ["M1", "M2", "둘 다 동일", "판단 불가"],
        correctIndex: 0,
        explanation: "M2는 검증 오차가 크게 나빠 과적합이고, M1이 더 안정적이다."
        },
        {
        id: 11,
        stem: "다음 중 최소 제곱법(Closed-form)을 사용할 때 주의해야 할 상황은?",
        options: [
            "입력 차원이 매우 크고, 특징 수가 수천~수만에 이르는 경우",
            "데이터가 매우 적은 경우",
            "비선형 회귀를 하고 싶은 경우",
            "이진 분류를 하고 싶은 경우"
        ],
        correctIndex: 0,
        explanation: "차원이 크면 역행렬 계산 등 행렬 연산 비용이 급격히 커진다."
        },
        {
        id: 12,
        stem: "단순 선형 회귀 ŷ = Wx + b 에 대해 손실 L = (ŷ - y)^2, 학습률 α = 0.1.\n현재 x=2, y=1, W=0, b=0일 때, 한 번의 업데이트 후 W 값은?\n(단, ∂L/∂W = 2(ŷ - y)x)",
        options: ["-0.4", "-0.2", "0.2", "0.4"],
        correctIndex: 3,
        explanation: "ŷ=0, (ŷ-y)=-1, ∂L/∂W=-4 → W_new = 0 - 0.1*(-4) = 0.4."
        },
        {
        id: 13,
        stem: "다음은 서로 다른 학습률로 실험한 결과이다.\n\n- α=0.001: 손실이 매우 천천히 감소, 수백 에폭 필요\n- α=1.0: 초기 몇 스텝 후 손실이 급격히 증가하며 발산\n- α=0.05: 손실이 빠르게 감소 후, 작은 변동을 보이며 안정됨\n\n가장 적절한 학습률 설정은?",
        options: ["0.001", "1.0", "0.05", "학습률은 성능에 영향을 주지 않는다."],
        correctIndex: 2,
        explanation: "너무 작으면 느리고, 너무 크면 발산하므로 0.05가 가장 안정적이다."
        },
        {
        id: 14,
        stem: "이진 분류 문제에서, 한 노드의 양성 비율이 0.5에서 0.6으로 변했다고 하자.\n이 변화에 대해 엔트로피가 지니 계수보다 더 민감하게 변화하는 이유로 가장 적절한 것은?",
        options: [
            "엔트로피는 로그 함수를 사용해 균등 혼합 근처에서 기울기가 더 크기 때문이다.",
            "지니 계수는 로그 함수를 쓰지 않아 항상 값이 0이다.",
            "지니 계수는 클래스가 2개일 때 정의되지 않는다.",
            "엔트로피는 항상 0~0.5 사이의 값만 갖는다."
        ],
        correctIndex: 0,
        explanation: "균등 혼합(0.5 근처)에서 엔트로피 곡선이 더 가파르다."
        },
        {
        id: 15,
        stem: "한 이진 분류 모델의 결과가 다음과 같다.\n\nTP=40, FN=10, FP=20, TN=30\n\n이때 정확도(Accuracy)와 정밀도(Precision)를 올바르게 계산한 것은?",
        options: [
            "Accuracy = 70/100, Precision = 40/60",
            "Accuracy = 70/100, Precision = 40/50",
            "Accuracy = 80/100, Precision = 40/60",
            "Accuracy = 80/100, Precision = 40/50"
        ],
        correctIndex: 0,
        explanation: "전체 100개 → Accuracy = (40+30)/100 = 70/100, Precision = 40/(40+20) = 40/60."
        },
        {
        id: 16,
        stem: "다음 상황에서 특이도(Specificity)를 특히 중시해야 하는 경우는?",
        options: [
            "암 진단 시스템 (양성 환자를 놓치면 큰일)",
            "화재 감지 시스템 (불을 놓치면 큰일)",
            "범죄 용의자 선별 시스템 (무고한 사람을 범죄자로 분류하면 큰 피해)",
            "스팸 메일 필터 (정상 메일을 스팸으로 분류하는 게 더 나쁨)"
        ],
        correctIndex: 2,
        explanation: "특이도는 실제 음성을 음성으로 맞히는 비율로, 무고한 사람을 FP로 만드는 것을 막는 데 중요하다."
        },
        {
        id: 17,
        stem: "다음 중 단층 퍼셉트론으로 해결 가능한 문제는?",
        options: ["XOR", "AND 또는 OR", "원 모양 클래스 분리", "나선형 패턴 분류"],
        correctIndex: 1,
        explanation: "AND/OR는 선형 분리가 가능하지만 XOR, 원형, 나선형 패턴은 단층 퍼셉트론으로 어렵다."
        },
        {
        id: 18,
        stem: "어떤 신경망에서 은닉층에 선형 활성화만 사용하고, 여러 층을 깊게 쌓았다고 하자.\n이때 표현할 수 있는 함수의 형태는?",
        options: [
            "임의의 비선형 함수",
            "입력에 대한 복잡한 다항식",
            "결국 하나의 선형 변환",
            "항상 상수 함수"
        ],
        correctIndex: 2,
        explanation: "선형 변환의 합성은 다시 선형이므로, 깊어도 전체적으로 선형 모델이다."
        },
        {
        id: 19,
        stem: "Sigmoid 함수 σ(x)에 대한 설명 중 옳은 것은?",
        options: [
            "모든 x에서 기울기가 1이다.",
            "x=0 근처에서 기울기가 최대이며, |x|가 커질수록 기울기가 0에 가까워진다.",
            "x가 매우 커질수록 기울기가 무한대로 커진다.",
            "항상 그래디언트 소멸 문제를 막아준다."
        ],
        correctIndex: 1,
        explanation: "Sigmoid는 양끝 포화 구간에서 기울기가 거의 0이 되어 gradient 소멸을 유발할 수 있다."
        },
        {
        id: 20,
        stem: "단일 뉴런에서 z = wx, 출력 ŷ = z(선형), 손실 L = 1/2(ŷ - y)^2일 때,\n∂L/∂w를 올바르게 표현한 것은?",
        options: ["(ŷ - y)", "(ŷ - y)x", "2(ŷ - y)", "2(ŷ - y)x"],
        correctIndex: 1,
        explanation: "L을 z에 대해 미분 후 체인 룰을 적용하면 (ŷ - y)·x가 된다."
        },
        {
        id: 21,
        stem: "MLP에서 한 가중치 w_ij에 대한 기울기를\n∂E/∂w_ij = (∂E/∂o_j) · (∂o_j/∂net_j) · (∂net_j/∂w_ij)로 나누어 보는 이유로 가장 적절한 것은?",
        options: [
            "역전파 구현을 위해 층별로 기여도를 재사용하기 위해",
            "편향 항을 제거하기 위해",
            "학습률을 자동으로 조정하기 위해",
            "활성화 함수를 제거하기 위해"
        ],
        correctIndex: 0,
        explanation: "오차 영향·활성화 영향·입력/가중치 영향을 분리하면 역전파를 체계적으로 계산·재사용할 수 있다."
        },
        {
        id: 22,
        stem: "다층 퍼셉트론에 대한 설명 중 가장 적절한 것은?",
        options: [
            "은닉층이 여러 개 있어도 입력–출력 사이에 활성화 함수가 없으면 선형 모델이다.",
            "은닉층이 많으면 항상 과적합이 발생한다.",
            "은닉층 하나당 하나의 데이터만 처리할 수 있다.",
            "은닉층이 여러 개여도 항상 표현력은 단층과 동일하다."
        ],
        correctIndex: 0,
        explanation: "비선형 활성화가 없으면 깊이를 늘려도 선형 변환의 합성일 뿐이다."
        },
        {
        id: 23,
        stem: "아주 깊은 네트워크에서, 역전파 시 초기 층의 기울기가 거의 0이 되어 학습이 잘 되지 않는다.\n이 현상은?",
        options: ["그래디언트 폭발", "그래디언트 소멸", "드롭아웃", "과적합"],
        correctIndex: 1,
        explanation: "앞단으로 갈수록 gradient가 0에 수렴하는 현상이 그래디언트 소멸이다."
        },
        {
        id: 24,
        stem: "다음 중 ReLU가 Sigmoid보다 더 적절할 가능성이 큰 상황은?",
        options: [
            "얕은 네트워크에서 출력층에 확률값(0~1)을 바로 만들고 싶을 때",
            "매우 깊은 네트워크에서 그래디언트 소멸을 줄이고 싶을 때",
            "모든 레이어에서 출력이 0~1 사이여야 할 때",
            "항상 양수만 출력해야 할 때"
        ],
        correctIndex: 1,
        explanation: "깊은 네트워크에서는 ReLU 계열이 Sigmoid보다 gradient 소멸에 강하다."
        },
        {
        id: 25,
        stem: "다음 설명과 가장 잘 맞는 학습 방식은?\n\n“전체 데이터는 너무 커서 한 번에 모두 메모리에 올리기 어렵고,\n샘플 하나씩 업데이트하면 너무 noisy하다.\n그래서 수십~수백 개 단위로 묶어서 한 번씩 업데이트해 적당한 안정성과 효율을 얻고 싶다.”",
        options: [
            "순수 온라인 학습(SGD, 샘플 1개)",
            "풀 배치 학습(전체 데이터 한 번에)",
            "미니배치 학습",
            "학습과 무관한 배치 정규화"
        ],
        correctIndex: 2,
        explanation: "샘플 1개와 전체 사이, 1 < batch size < 전체인 미니배치 학습 설명이다."
        },
        {
        id: 26,
        stem: "훈련/검증 손실 곡선이 다음과 같다.\n\n- 에폭 1~20: 훈련 손실 ↓, 검증 손실 ↓\n- 에폭 20 이후: 훈련 손실 계속 ↓, 검증 손실 ↑\n\n이 경우 조기 종료를 적용한다면, 어떤 지점을 선택하는 것이 가장 자연스러운가?",
        options: ["에폭 1", "에폭 10", "에폭 20 부근(검증 손실 최소)", "에폭 40(훈련 손실 최소)"],
        correctIndex: 2,
        explanation: "조기 종료는 보통 검증 손실이 최소가 되는 지점을 기준으로 한다."
        },
        {
        id: 27,
        stem: "다음 모델링 목표에 가장 적합한 규제 조합은?\n\n“특징 수가 매우 많고, 그 중 극히 일부만 중요한 상황이다.\n중요하지 않은 특징의 가중치는 대부분 0에 가깝게 만들고 싶다.”",
        options: ["L1 규제", "L2 규제", "L1+L2 규제", "규제를 사용하지 않음"],
        correctIndex: 0,
        explanation: "L1 규제는 많은 가중치를 정확히 0으로 보내 희소한 모델을 만든다."
        },
        {
        id: 28,
        stem: "드롭아웃(dropout)에 대한 설명 중 옳지 않은 것은?",
        options: [
            "학습 시 일부 뉴런을 랜덤하게 끄는 방식이다.",
            "특정 뉴런에 과도하게 의존하는 것을 막아 과적합을 줄이는 효과가 있다.",
            "테스트 시에도 학습 때와 동일하게 뉴런을 랜덤하게 끄는 것이 일반적이다.",
            "여러 서브 네트워크를 학습한 뒤, 테스트 시 이들을 합쳐 쓰는 앙상블 효과를 낸다고 볼 수 있다."
        ],
        correctIndex: 2,
        explanation: "테스트 시에는 뉴런을 끄지 않고 전체 네트워크를 사용한다."
        },
        {
        id: 29,
        stem: "Q-러닝에서 다음 상태 전이와 보상이 관측되었다.\n\n- 현재 상태 s, 행동 a\n- 보상 r = 5\n- 다음 상태 s'에서 가능한 행동들의 Q값 최대값 = 10\n- 현재 Q(s,a) = 2\n- 할인률 γ = 0.9, 학습률 α = 0.1\n\nQ-러닝 업데이트 후 새로운 Q(s,a)는?\n(Q_new = Q + α[r + γ max Q(s',a') - Q])",
        options: ["2", "3.2", "4", "14"],
        correctIndex: 1,
        explanation: "target = 5 + 0.9·10 = 14, 차이 = 12, Q_new = 2 + 0.1·12 = 3.2."
        },
        {
        id: 30,
        stem: "one-hot 인코딩의 한계에 대한 설명으로 가장 적절한 것은?",
        options: [
            "단어 간 유사도를 거리/각도 등으로 표현하기 어렵다.",
            "차원이 항상 2차원 이하로 제한된다.",
            "새로운 단어가 생겨도 차원을 늘릴 필요가 없다.",
            "차원이 너무 작아 복잡한 표현이 불가능하다."
        ],
        correctIndex: 0,
        explanation: "one-hot 벡터는 서로 직교라 의미적 유사성을 반영하기 어렵다."
        },
        {
        id: 31,
        stem: "Skip-gram Word2Vec 모델에서, 입력 중심 단어 w_c와 주변 단어 w_o의 임베딩을 각각 v_c, u_o라 하자.\nnegative sampling을 사용할 때, 학습 목표를 가장 잘 설명한 것은?",
        options: [
            "v_c와 u_o의 내적을 최소화하고, negative 샘플과의 내적은 최대화한다.",
            "v_c와 u_o의 내적을 최대화하고, negative 샘플과의 내적은 최소화한다.",
            "모든 단어 쌍의 내적을 항상 0으로 만든다.",
            "one-hot 벡터를 직접 조정한다."
        ],
        correctIndex: 1,
        explanation: "실제 주변 단어는 가깝게(내적↑), negative 샘플은 멀게(내적↓) 만든다."
        },
        {
        id: 32,
        stem: "RNN 기반 언어 모델의 한계로 옳지 않은 것은?",
        options: [
            "긴 문장을 처리할수록 앞쪽 단어 정보가 뒤로 가면서 희미해질 수 있다.",
            "순차적인 구조라 병렬 처리에 불리하다.",
            "매우 긴 의존 관계 학습이 어렵다.",
            "항상 입력 문장을 동시에(한 번에) 처리할 수 있어 GPU 병렬화에 최적화된다."
        ],
        correctIndex: 3,
        explanation: "RNN은 순차 구조라 전체를 동시에 처리하기 어렵고 병렬화에 불리하다."
        },
        {
        id: 33,
        stem: "Self-Attention에서 Query(Q), Key(K), Value(V) 벡터에 대한 설명 중 가장 적절한 것은?",
        options: [
            "Q는 단어의 위치 정보를, K는 단어의 정답 레이블을, V는 손실 값을 의미한다.",
            "Q는 비교 기준이 되는 현재 단어, K는 모든 단어의 특징, V는 실제로 전달되는 정보를 의미한다.",
            "Q는 항상 0 벡터, K는 항상 1 벡터, V는 항상 랜덤 벡터이다.",
            "Q, K, V는 각각 Encoder, Decoder, Loss를 의미한다."
        ],
        correctIndex: 1,
        explanation: "Q는 무엇을 볼지, K는 어떤 단어인지, V는 그 단어의 정보를 담는 벡터다."
        },
        {
        id: 34,
        stem: "Transformer에서 Positional Encoding의 주요 목적은?",
        options: [
            "단어의 의미를 바꾸기 위해",
            "단어의 위치(문장 내 순서)를 벡터에 포함시켜, Self-Attention이 순서를 고려할 수 있게 하기 위해",
            "모델 파라미터 수를 줄이기 위해",
            "손실 함수를 바꾸기 위해"
        ],
        correctIndex: 1,
        explanation: "Self-Attention만으로는 순서 개념이 없으므로 위치 정보를 embedding에 더해준다."
        },
        {
        id: 35,
        stem: "Transformer에서 Encoder와 Decoder의 역할을 올바르게 설명한 것은?",
        options: [
            "Encoder는 다음 단어를 생성하고, Decoder는 입력 문장을 인코딩한다.",
            "Encoder는 입력 문장의 문맥 정보를 추출하고, Decoder는 이 정보를 사용해 출력 문장을 생성한다.",
            "둘 다 입력 문장을 인코딩만 한다.",
            "둘 다 Decoder-only 구조로, 미래 단어를 항상 보지 못한다."
        ],
        correctIndex: 1,
        explanation: "Encoder는 문맥 이해, Decoder는 그 정보를 바탕으로 출력 문장을 생성한다."
        },
        {
        id: 36,
        stem: "BERT의 학습 방식에 대한 설명으로 옳은 것은?",
        options: [
            "Decoder-only 구조로, 왼쪽 단어만 보고 오른쪽을 예측한다.",
            "Encoder-only 구조로, 양방향 문맥을 함께 보고 가운데 단어를 예측하는 식으로 학습한다.",
            "강화학습으로 보상을 최적화하는 방식으로 학습한다.",
            "RNN 기반으로 순차적으로 단어를 처리한다."
        ],
        correctIndex: 1,
        explanation: "BERT는 Encoder-only 양방향 언어 모델로, 가운데 단어 예측 등으로 학습한다."
        },
        {
        id: 37,
        stem: "GPT 계열 모델의 기본 학습 문제를 가장 잘 표현한 것은?",
        options: [
            "문장 중 임의의 단어를 가리고 주변 단어로 예측",
            "다음 상태의 보상을 최대화하는 정책 학습",
            "과거 토큰들을 보고 다음 토큰을 예측하는 문제",
            "입력 문장 전체를 한 번에 보고 중앙 단어를 예측하는 문제"
        ],
        correctIndex: 2,
        explanation: "GPT는 Decoder-only 구조로 “다음 단어 예측”을 기본으로 학습한다."
        },
        {
        id: 38,
        stem: "Instruction tuning(지시 튜닝)에 대한 설명으로 가장 적절한 것은?",
        options: [
            "웹 텍스트만으로 다음 단어 예측을 학습하는 사전 학습 단계이다.",
            "질문–답변, 지시–응답 형식의 데이터로 추가 학습하여, 사용자의 지시를 더 잘 따르도록 만드는 단계이다.",
            "모델의 파라미터 수를 강제로 줄이는 정규화 기법이다.",
            "모든 언어를 하나의 공통 임베딩으로 압축하는 방법이다."
        ],
        correctIndex: 1,
        explanation: "Instruction tuning은 지시/질문에 맞게 응답하는 능력을 강화하는 파인튜닝이다."
        }
    ]
    },
      set6: {
  id: "set6",
  name: "실전 문제집 6",
  tag: "6회",
  questions: [
    {
      id: 1,
      stem: "다음 중 ‘기계학습’과 귀납적 추론에 대한 설명으로 가장 적절한 것은?",
      options: [
        "전문가가 이론을 먼저 세우고, 그 이론이 맞는지 데이터를 통해 검증하는 과정이 기계학습이다.",
        "기계학습은 데이터에서 패턴을 추론해 일반적인 규칙을 얻는 귀납적 추론을 사용한다.",
        "기계학습에서 모델은 항상 사람이 쓴 규칙을 그대로 따르며, 데이터는 단지 검증용으로만 사용된다.",
        "연역적 추론만을 사용하는 모델만이 ‘기계학습’이라고 부를 수 있다."
      ],
      correctIndex: 1,
      explanation: "기계학습은 데이터(사례)로부터 일반적인 규칙을 추론하는 귀납적 추론에 기반한다."
    },
    {
      id: 2,
      stem: "다음 중 ‘과적합(Overfitting)’을 가장 잘 설명하는 상황은?",
      options: [
        "훈련 정확도와 검증 정확도가 모두 낮아, 데이터 패턴을 거의 학습하지 못한 상태",
        "훈련 정확도는 매우 높지만, 검증 정확도가 낮고, 학습 데이터를 조금만 바꿔도 예측이 크게 달라지는 상태",
        "훈련 정확도와 검증 정확도가 모두 높고 거의 비슷한 상태",
        "훈련 데이터를 거의 사용하지 않고도 높은 성능을 보이는 상태"
      ],
      correctIndex: 1,
      explanation: "과적합은 훈련 데이터에 과도하게 맞추어 일반화가 나빠진 상태로, train–val 간 차이가 크게 나타난다."
    },
    {
      id: 3,
      stem: "다음 중 과적합을 줄이기 위한 전략으로 ‘올바르지 않은 것’을 고르시오.",
      options: [
        "훈련 데이터 일부를 떼어낸 검증(validation) 데이터를 기준으로 조기 종료(early stopping)를 적용한다.",
        "모델 복잡도가 데이터 규모에 비해 지나치게 크다면, 층 수·파라미터 수를 줄인다.",
        "훈련 데이터가 적다면 데이터 증강(data augmentation)을 통해 데이터 다양성을 높인다.",
        "훈련 손실이 0에 가까워질 때까지 에폭 수를 계속 늘려서 학습을 반복한다."
      ],
      correctIndex: 3,
      explanation: "훈련 손실이 0에 가까워질 때까지 계속 학습하면 오히려 과적합이 심해질 수 있다."
    },
    {
      id: 4,
      stem: "다음 중 ‘과소적합(Underfitting)’의 원인으로 보기 어려운 것은?",
      options: [
        "모델이 너무 단순해 데이터의 복잡한 패턴을 표현하지 못한다.",
        "입력 특징이 데이터의 중요한 정보를 충분히 담지 못한다.",
        "학습을 너무 짧은 에폭 동안만 수행했다.",
        "훈련 데이터에 비해 파라미터 수가 지나치게 많아졌다."
      ],
      correctIndex: 3,
      explanation: "파라미터 수가 지나치게 많으면 보통 과적합 위험이 커지고, 과소적합의 전형적인 원인은 아니다."
    },
    {
      id: 5,
      stem: "세 개의 모델 A, B, C에 대해 다음과 같은 결과를 얻었다.\n\n- 모델 A: 훈련 정확도 0.95, 검증 정확도 0.55\n- 모델 B: 훈련 정확도 0.78, 검증 정확도 0.76\n- 모델 C: 훈련 정확도 0.65, 검증 정확도 0.64\n\n편향–분산 관점에서 가장 적절한 해석은?",
      options: [
        "A는 높은 편향, 낮은 분산 / B는 낮은 편향, 높은 분산 / C는 낮은 편향, 낮은 분산",
        "A는 낮은 편향, 높은 분산 / B는 낮은 편향, 낮은 분산 / C는 높은 편향, 낮은 분산",
        "A는 낮은 편향, 낮은 분산 / B는 높은 편향, 높은 분산 / C는 낮은 편향, 높은 분산",
        "A는 높은 편향, 높은 분산 / B는 낮은 편향, 낮은 분산 / C는 높은 편향, 높은 분산"
      ],
      correctIndex: 1,
      explanation: "A: train 높고 val 낮 → 낮은 편향·높은 분산, B: 둘 다 높고 비슷 → 낮은 편향·낮은 분산, C: 둘 다 낮음 → 높은 편향·낮은 분산에 가깝다."
    },
    {
      id: 6,
      stem: "다음 중 비지도 학습의 대표적인 과제로 올바르게 짝지어진 것은?",
      options: [
        "군집화 – 레이블이 있는 데이터로 경계면을 학습해 새로운 샘플의 클래스를 예측",
        "밀도추정 – 고차원 데이터를 저차원으로 압축하면서 중요한 구조만 유지",
        "차원축소 – 데이터가 어떤 확률분포에서 생성되었는지 추정",
        "이상치 탐지 – 일반적인 패턴과 크게 다른 데이터 포인트를 식별"
      ],
      correctIndex: 3,
      explanation: "군집화/밀도추정/차원축소/이상치 탐지는 모두 비지도 학습인데, 이상치 탐지는 일반적인 패턴과 다른 포인트를 찾는 작업이다."
    },
    {
      id: 7,
      stem: "다음 설명이 가리키는 학습 방식은 무엇인가?\n\n“사람이 정답 레이블을 붙여주지 않아도, 데이터의 일부를 가리고 나머지로 이를 예측하게 하여 pseudo-label을 만들어 학습하는 방식”",
      options: [
        "지도 학습",
        "비지도 학습",
        "자기 지도 학습",
        "강화 학습"
      ],
      correctIndex: 2,
      explanation: "데이터 일부를 가리고 나머지로 예측하는 방식은 자기 지도 학습(self-supervised learning)의 대표적 예다."
    },
    {
      id: 8,
      stem: "다음 중 ‘선형 회귀’ 모델로 접근하는 것이 상대적으로 적절한 상황은?",
      options: [
        "연령이 증가할수록, 어느 구간 이후에는 실업률이 다시 감소하는 U자형 관계가 나타나는 경우",
        "집 면적이 일정 범위에서 증가할수록 평균적으로 집값이 거의 비례해 증가하는 경우",
        "원형 경계 안/밖으로 데이터가 나뉘어 있는 이진 분류 문제",
        "시계열 데이터에서 계절성·주기성이 강하게 나타나는 경우"
      ],
      correctIndex: 1,
      explanation: "면적과 가격이 거의 비례 관계일 때는 1차 선형 회귀가 적합할 가능성이 높다."
    },
    {
      id: 9,
      stem: "회귀 문제에서 손실 함수로 제곱 오차(Mean Squared Error)를 많이 사용하는 이유로 가장 적절한 것은?",
      options: [
        "절댓값보다 제곱이 항상 더 작은 값을 주기 때문이다.",
        "제곱 오차는 미분이 불가능해 최적화가 더 어렵지만, 이론적으로 의미가 깊기 때문이다.",
        "제곱 오차는 미분이 가능하고, 오차가 클수록 더 큰 패널티를 주어 학습이 수월해지기 때문이다.",
        "제곱 오차를 쓰면 항상 과적합을 방지할 수 있기 때문이다."
      ],
      correctIndex: 2,
      explanation: "제곱 오차는 연속·미분 가능하고, 큰 오차에 더 큰 패널티를 줘 경사하강법 최적화에 자주 사용된다."
    },
    {
      id: 10,
      stem: "다음 중 최소제곱법(Closed-form solution)을 사용하기 어려운 상황을 고르시오.",
      options: [
        "입력 차원이 매우 크고, 특징 수가 수만 개에 이르며 역행렬 계산이 부담스러운 경우",
        "데이터 차원이 낮고, 샘플 수가 적은 경우",
        "데이터가 메모리에 충분히 들어가고, 학습을 자주 반복할 필요가 없는 경우",
        "모델이 간단한 1차 선형 회귀이고, 설명변수도 1~2개뿐인 경우"
      ],
      correctIndex: 0,
      explanation: "차원이 매우 크면 역행렬 계산 비용이 급격히 증가하므로, 반복 최적화(경사하강법)를 쓰는 편이 낫다."
    },
    {
      id: 11,
      stem: "다음 중 의사결정 트리(Decision Tree)와 선형 회귀 모델을 비교한 설명으로 옳은 것은?",
      options: [
        "둘 다 완전히 선형 모델이므로, 복잡한 비선형 경계를 학습할 수 없다.",
        "의사결정 트리는 분기 규칙을 통해 비선형 경계를 만들 수 있지만, 데이터 변화에 민감해 구조가 크게 바뀔 수 있다.",
        "선형 회귀는 계단형(비연속) 예측 값을 내지만, 트리는 연속적인 출력 값을 항상 생성한다.",
        "의사결정 트리는 미분이 가능하고, 선형 회귀는 미분이 불가능해서 경사하강법을 사용할 수 없다."
      ],
      correctIndex: 1,
      explanation: "트리는 분기 기반 비선형 경계를 만들지만, 작은 데이터 변화에도 구조가 크게 바뀌는 높은 분산(불안정성)의 특성을 가진다."
    },
    {
      id: 12,
      stem: "이진 분류 노드에서 양성 비율이 p일 때, 지니 계수 G와 엔트로피 H에 대한 설명으로 옳은 것은?\n(단, 클래스는 두 개라고 가정)",
      options: [
        "p=0.5일 때 지니 계수는 0, 엔트로피는 최대가 된다.",
        "p=0.5 근처에서 엔트로피는 지니 계수보다 변화가 더 민감하여, 거의 균등한 섞임에 더 민감하게 반응한다.",
        "클래스가 2개일 때 엔트로피는 항상 0이고, 지니 계수만 0~1 사이의 값을 가진다.",
        "지니 계수와 엔트로피는 항상 동일한 값을 가지므로, 둘 중 어느 것을 써도 수치가 완전히 같다."
      ],
      correctIndex: 1,
      explanation: "균등 혼합(0.5 근처)에서 엔트로피 곡선이 더 가파르므로, 섞임 정도 변화에 더 민감하게 반응한다."
    },
    {
      id: 13,
      stem: "어떤 분할 전/후 노드의 엔트로피가 다음과 같을 때, 정보 이득(Information Gain)을 올바르게 계산한 것은?\n\n- 부모 노드 엔트로피: 0.9\n- 자식 노드 1: 샘플 수 40개, 엔트로피 0.5\n- 자식 노드 2: 샘플 수 60개, 엔트로피 0.2\n",
      options: [
        "IG = 0.9 - (0.5 + 0.2) = 0.2",
        "IG = 0.9 - (0.4·0.5 + 0.6·0.2) = 0.9 - (0.2 + 0.12) = 0.58",
        "IG = 0.9 - (0.4·0.2 + 0.6·0.5) = 0.9 - 0.38 = 0.52",
        "IG = 0.9 - (0.5·0.2 + 0.5·0.5) = 0.9 - 0.35 = 0.55"
      ],
      correctIndex: 1,
      explanation: "가중 평균 엔트로피 = 0.4·0.5 + 0.6·0.2 = 0.2 + 0.12 = 0.32, IG = 0.9 - 0.32 = 0.58이다."
    },
    {
      id: 14,
      stem: "다음 이진 분류 결과에 대한 혼동 행렬이 있다.\n\n- 실제 양성: 80개 중 60개를 양성으로 맞추고, 20개를 음성으로 잘못 예측\n- 실제 음성: 20개 중 5개를 양성으로 잘못 예측, 15개를 음성으로 맞춤\n\n이 분류기의 민감도(Recall, Sensitivity)와 특이도(Specificity)를 올바르게 계산한 것은?",
      options: [
        "민감도 = 60/80, 특이도 = 15/20",
        "민감도 = 60/75, 특이도 = 15/20",
        "민감도 = 60/80, 특이도 = 15/35",
        "민감도 = 60/60, 특이도 = 15/20"
      ],
      correctIndex: 0,
      explanation: "TP=60, FN=20, FP=5, TN=15 → 민감도 = TP/(TP+FN)=60/80, 특이도 = TN/(TN+FP)=15/20이다."
    },
    {
      id: 15,
      stem: "아래 상황에서 가장 중요한 평가지표는 무엇인가?\n\n“암 진단 모델에서 양성 환자를 놓치는 경우(FN)가 치명적이며, 어느 정도 오경보(FP)는 허용 가능하다.”",
      options: [
        "정확도(Accuracy)",
        "특이도(Specificity)",
        "민감도(Recall, Sensitivity)",
        "정밀도(Precision)"
      ],
      correctIndex: 2,
      explanation: "놓치지 말아야 할 양성(암 환자)을 잘 잡는 것이 중요하므로, FN을 최소화하는 민감도가 핵심이다."
    },
    {
      id: 16,
      stem: "단층 퍼셉트론(Perceptron)으로는 XOR 문제를 풀 수 없다고 알려져 있다. 그 이유로 가장 적절한 것은?",
      options: [
        "XOR 문제는 연속적인 출력이 필요하기 때문이다.",
        "XOR 문제는 선형 분리(linearly separable)가 아니기 때문에, 단층 퍼셉트론의 단일 선형 경계로는 분리 불가능하다.",
        "퍼셉트론은 활성화 함수를 사용할 수 없기 때문이다.",
        "퍼셉트론은 입력 차원이 3 이상인 문제만 처리할 수 있기 때문이다."
      ],
      correctIndex: 1,
      explanation: "XOR은 선형 분리 불가능한 문제로, 하나의 직선(평면)으로는 두 클래스를 나눌 수 없다."
    },
    {
      id: 17,
      stem: "다층 퍼셉트론(MLP)에서 활성화 함수를 사용하는 가장 중요한 이유는 무엇인가?",
      options: [
        "가중치 업데이트를 불가능하게 만들어 과적합을 방지하기 위해",
        "선형 분류기를 여러 개 합쳐도 여전히 선형이기 때문에, 활성화 함수로 비선형성을 도입해 복잡한 패턴을 표현하기 위해",
        "모든 레이어의 출력을 0~1 사이로 강제하기 위해",
        "가중치의 개수를 줄여서 연산량을 감소시키기 위해"
      ],
      correctIndex: 1,
      explanation: "선형 변환을 여러 번 합성해도 전체는 선형이므로, 비선형 활성화 함수를 통해 비선형 함수 근사가 가능해진다."
    },
    {
      id: 18,
      stem: "역전파(Backpropagation)에서 한 가중치 w에 대한 기울기 ∂E/∂w를 세 개의 항으로 나누어 생각할 수 있다. 강의에서 강조한 ‘세 항’의 의미를 올바르게 나열한 것은?",
      options: [
        "입력 데이터 분산, 가중치 초기값, 학습률",
        "오차의 영향(∂E/∂o), 활성화 함수의 영향(∂o/∂net), 입력·가중치의 영향(∂net/∂w)",
        "정답 레이블, 손실 함수 종류, 최적화 알고리즘 종류",
        "편향, 분산, 일반화 오차"
      ],
      correctIndex: 1,
      explanation: "역전파에서 미분은 ‘오차의 영향·활성화 함수의 영향·입력×가중치의 영향’ 세 항으로 나누어 체인 룰로 계산한다."
    },
    {
      id: 19,
      stem: "심층 신경망에서 그래디언트 소멸(Vanishing Gradient)이 발생하는 주된 이유로 가장 적절한 것은?",
      options: [
        "Softmax 함수를 사용하면 항상 그래디언트가 0이 되기 때문이다.",
        "Sigmoid 같은 활성화 함수가 포화 영역에서 미분값이 매우 작아지고, 이를 여러 층으로 곱해 나갈수록 앞단 기울기가 거의 0에 가까워지기 때문이다.",
        "가중치를 항상 0으로 초기화하기 때문이다.",
        "에폭 수가 너무 적기 때문이다."
      ],
      correctIndex: 1,
      explanation: "Sigmoid의 포화 구간에서는 기울기가 매우 작고, 깊은 네트워크에서는 이 작은 값이 계속 곱해져 앞단에서 gradient가 거의 0이 된다."
    },
    {
      id: 20,
      stem: "Xavier 초기화에 대한 설명으로 옳은 것은?\n(강조: Sigmoid 계열에서 중요@@@)",
      options: [
        "모든 가중치를 0으로 초기화하여 symmetry를 보장한다.",
        "입력과 출력의 분산이 일정하게 유지되도록, 가중치를 적절한 분포에서 초기화해 순·역전파 시 값이 너무 커지거나 작아지지 않게 한다.",
        "큰 정규분포에서 가중치를 뽑아, gradient를 인위적으로 키운다.",
        "항상 1과 -1만을 사용하는 이진 가중치 초기화 방법이다."
      ],
      correctIndex: 1,
      explanation: "Xavier 초기화는 각 층의 입력/출력 분산이 유지되도록 가중치를 초기화해, 그래디언트가 안정적으로 전파되도록 돕는다."
    },
    {
      id: 21,
      stem: "다중 클래스 분류에서 출력층에 Softmax + 교차 엔트로피(Cross-Entropy)를 사용하는 주된 이유로 가장 적절한 것은?",
      options: [
        "Softmax는 미분이 불가능하지만, 교차 엔트로피는 항상 0이기 때문에 최적화가 쉽다.",
        "Softmax는 각 클래스의 확률 분포를 만들고, 교차 엔트로피는 정답 분포와 예측 분포 간의 ‘거리’를 측정해, 확률 관점에서 손실을 정의해 주기 때문이다.",
        "MSE 대신 교차 엔트로피를 사용하면 과적합이 자동으로 사라진다.",
        "Softmax와 교차 엔트로피는 이진 분류에서만 사용 가능하다."
      ],
      correctIndex: 1,
      explanation: "Softmax로 확률 분포를 만들고, 교차 엔트로피로 두 분포 간 차이를 측정하는 것이 다중 클래스 분류에서 표준 조합이다."
    },
    {
      id: 22,
      stem: "온라인 학습(SGD), 배치 학습(Batch), 미니배치 학습(Mini-batch)을 비교한 설명으로 옳은 것은?",
      options: [
        "온라인 학습은 전체 데이터를 한 번에 사용하여 가장 안정적인 업데이트를 제공한다.",
        "배치 학습은 한 번에 하나의 샘플만을 사용하므로 노이즈에 매우 민감하다.",
        "미니배치 학습은 1개보다 크고 전체보다 작은 묶음으로 업데이트하여, 계산 효율과 통계적 안정성을 동시에 어느 정도 얻는다.",
        "세 방법은 모두 동일한 방식이며, 단지 이름만 다르다."
      ],
      correctIndex: 2,
      explanation: "미니배치 학습은 온라인(SGD)의 노이즈와 배치의 큰 연산 부담 사이의 타협안으로 널리 사용된다."
    },
    {
      id: 23,
      stem: "다음 중 L1, L2 가중치 규제(Regularization)의 효과에 대한 설명으로 옳은 것은?",
      options: [
        "L1 규제는 모든 가중치를 거의 동일한 크기로 만들고, L2 규제는 일부 가중치를 정확히 0으로 만든다.",
        "L1 규제는 가중치의 절댓값 합에 페널티를 주어 많은 가중치를 0으로 만들어 특징 선택 효과를 낼 수 있다.",
        "L2 규제는 가중치의 절댓값 합에 페널티를 주어, 일부 가중치를 완전히 제거한다.",
        "L1/L2 규제는 과적합과는 무관하며, 단지 학습 속도만 바꾼다."
      ],
      correctIndex: 1,
      explanation: "L1은 절댓값 페널티로 희소한(w=0인) 해를 만들기 쉽고, L2는 제곱 페널티로 가중치를 부드럽게 줄인다."
    },
    {
      id: 24,
      stem: "드롭아웃(Dropout)에 대한 설명으로 옳지 않은 것은?",
      options: [
        "학습 시 일부 뉴런을 랜덤하게 비활성화하여, 특정 뉴런에 과도하게 의존하는 것을 막는다.",
        "학습 과정에서 매번 다른 서브 네트워크를 학습하는 효과가 있어, 일종의 앙상블 효과를 낸다.",
        "테스트(추론) 시에도 학습 때처럼 임의로 뉴런을 꺼야 더 좋은 일반화 성능을 얻는다.",
        "과적합을 줄이는 regularization 기법 중 하나로 볼 수 있다."
      ],
      correctIndex: 2,
      explanation: "테스트 시에는 보통 드롭아웃을 사용하지 않고 전체 뉴런을 사용하거나, 학습 시 확률에 맞게 스케일만 조정한다."
    },
    {
      id: 25,
      stem: "데이터 증강(Data Augmentation)의 주된 효과로 가장 적절한 것은?",
      options: [
        "훈련 데이터 수는 그대로 두고, 손실 함수를 자동으로 바꿔준다.",
        "원본 데이터에 다양한 변형(회전, 자르기 등)을 적용해 데이터 다양성을 늘리고, 모델이 특정 위치·각도에 덜 민감하도록 만들어 일반화 성능을 향상시킨다.",
        "훈련 속도를 빠르게 하기 위해 사용하는 최적화 알고리즘의 한 종류이다.",
        "훈련 데이터에 인위적인 노이즈를 추가하여 항상 과소적합을 유도한다."
      ],
      correctIndex: 1,
      explanation: "데이터 증강은 실제로 더 많은 상황을 보는 효과를 주어 과적합을 줄이고 일반화를 도와준다."
    },
    {
      id: 26,
      stem: "Q-러닝(Q-learning)에 대한 설명으로 가장 적절한 것은?\n(강조: model-free, Q-table 개념)",
      options: [
        "환경의 전이 확률과 보상 함수를 정확히 알고 있어야만 동작하는 모델 기반 강화학습이다.",
        "상태–행동 쌍에 대한 Q값을 테이블 형태로 학습하며, 환경의 전이 모델 없이도 경험만으로 최적 정책을 근사할 수 있는 model-free 알고리즘이다.",
        "Q-러닝에서는 항상 즉시 보상만 고려하고, 미래 보상은 무시한다.",
        "Q-러닝은 지도 학습의 한 종류로, 레이블이 있는 데이터로만 학습한다."
      ],
      correctIndex: 1,
      explanation: "Q-러닝은 상태–행동 가치 Q(s,a)를 직접 업데이트하는 model-free 강화학습 알고리즘이다."
    },
    {
      id: 27,
      stem: "Q-러닝의 업데이트 식\nQ(s,a) ← Q(s,a) + α[r + γ max_{a'} Q(s',a') − Q(s,a)]\n에서 대괄호 안의 항(r + γ max Q − Q(s,a))이 의미하는 것은 무엇인가?",
      options: [
        "현재 상태의 손실 함수 값",
        "학습률을 조절하는 하이퍼파라미터",
        "TD 오차(Temporal-Difference error): 예상한 가치와 실제로 관측된 target 가치의 차이",
        "환경의 전이 확률"
      ],
      correctIndex: 2,
      explanation: "r + γ max Q(s',a')는 target, Q(s,a)는 현재 추정치로, 둘의 차이가 TD 오차이다."
    },
    {
      id: 28,
      stem: "다음 중 one-hot 인코딩과 Word2Vec 임베딩을 비교한 설명으로 옳은 것은?",
      options: [
        "one-hot 벡터는 단어 간 유사도를 잘 반영하지만, Word2Vec은 이를 반영하지 못한다.",
        "one-hot 벡터는 차원이 단어 수만큼 커지며, 서로 직교라 유사도 표현이 어렵다. Word2Vec 임베딩은 상대적으로 낮은 차원에서 의미적 유사성을 거리/각도로 표현할 수 있다.",
        "Word2Vec은 항상 단어의 등장 빈도만을 저장하는 벡터이다.",
        "one-hot과 Word2Vec은 모두 차원이 매우 작아서 표현력이 떨어진다."
      ],
      correctIndex: 1,
      explanation: "one-hot은 희소·고차원·유사도 미반영, Word2Vec은 밀집·저차원·의미적 유사도 반영이 핵심 차이이다."
    },
    {
      id: 29,
      stem: "Word2Vec의 Skip-gram 모델과 CBOW 모델에 대한 설명으로 옳은 것은?",
      options: [
        "Skip-gram은 주변 단어로 중심 단어를 예측하고, CBOW는 중심 단어로 주변 단어를 예측한다.",
        "Skip-gram은 중심 단어로 주변 단어를 예측하고, CBOW는 주변 단어들의 정보를 이용해 중심 단어를 예측한다.",
        "두 모델 모두 입력과 출력이 동일하며, 차이점이 없다.",
        "CBOW는 항상 one-hot 인코딩을 사용하지 않는다."
      ],
      correctIndex: 1,
      explanation: "CBOW: 주변 → 중심, Skip-gram: 중심 → 주변 단어 예측 구조다."
    },
    {
      id: 30,
      stem: "Skip-gram Word2Vec에서 Negative Sampling을 사용하는 주된 이유는 무엇인가?",
      options: [
        "모든 단어 쌍의 내적을 0으로 만들기 위해서",
        "문장에 등장하는 모든 단어가 서로 가까워지도록 하기 위해서",
        "실제로 자주 같이 등장하는 단어쌍은 내적을 크게, 무관한 단어쌍은 내적을 작게 만들면서도, 모든 단어에 대해 Softmax를 계산하는 막대한 비용을 줄이기 위해서",
        "단어 사전 크기를 줄이기 위해 특정 단어를 제거하기 위해서"
      ],
      correctIndex: 2,
      explanation: "Negative Sampling은 일부 negative 예만 뽑아 학습해 계산량을 줄이면서, co-occurrence 구조를 학습한다."
    },
    {
      id: 31,
      stem: "RNN 기반 언어 모델의 한계로 가장 적절한 것은?",
      options: [
        "각 시점이 완전히 독립이라 문맥 정보를 전혀 사용할 수 없다.",
        "문장을 한 번에 병렬 처리할 수 있어 긴 문장에서도 항상 빠르게 학습된다.",
        "긴 문장에서 앞부분의 정보가 뒷부분으로 전파되는 과정에서 그래디언트 소멸/폭발 문제가 발생하기 쉽고, 순차 구조라 병렬 처리에도 불리하다.",
        "항상 고정 길이 문장만 처리 가능하다."
      ],
      correctIndex: 2,
      explanation: "RNN은 순차적으로 처리하는 구조라 병렬성이 떨어지고, 긴 시퀀스에서 gradient 소실/폭발 문제가 크다."
    },
    {
      id: 32,
      stem: "Transformer의 Self-Attention에서 Query(Q), Key(K), Value(V)의 역할로 가장 적절한 것은?",
      options: [
        "Q는 단어의 위치, K는 단어의 품사 태그, V는 단어의 빈도를 나타낸다.",
        "Q는 비교 기준이 되는 현재 단어, K는 비교 대상이 되는 모든 단어의 특징, V는 Attention 가중치를 적용한 후 실제로 전달되는 정보를 의미한다.",
        "Q, K, V는 각각 Encoder, Decoder, Loss를 의미한다.",
        "Q와 K는 항상 같은 값이고, V는 0 벡터이다."
      ],
      correctIndex: 1,
      explanation: "Self-Attention에서 Q는 ‘무엇을 볼지’, K는 ‘무엇이 있는지’, V는 ‘어떤 정보를 넘길지’를 나타낸다."
    },
    {
      id: 33,
      stem: "Transformer에서 Positional Encoding이 없다면 발생할 수 있는 문제를 가장 잘 설명한 것은?",
      options: [
        "모델 파라미터 수가 너무 늘어나 학습이 불가능해진다.",
        "Self-Attention이 단어 순서를 고려할 수 없어, 같은 단어들이 섞여 있는 문장을 서로 구분하지 못한다.",
        "Softmax가 동작하지 않는다.",
        "RNN처럼 순차 처리가 강제된다."
      ],
      correctIndex: 1,
      explanation: "Self-Attention만으로는 단어 간 순서 정보가 없으므로, 위치 정보를 인코딩해 넣어야 순서를 인식할 수 있다."
    },
    {
      id: 34,
      stem: "BERT와 GPT를 비교한 설명으로 가장 옳은 것은?",
      options: [
        "둘 다 Encoder만 사용하는 구조이며, 가운데 단어를 예측하는 Masked LM으로 학습한다.",
        "둘 다 Decoder-only 구조이며, 다음 단어 예측(autoregressive)만 학습한다.",
        "BERT는 Encoder-only로 양방향 문맥을 사용해 가운데 단어를 예측하고, GPT는 Decoder-only로 왼쪽 문맥만 보고 다음 단어를 예측한다.",
        "BERT는 RNN 기반, GPT는 CNN 기반이다."
      ],
      correctIndex: 2,
      explanation: "BERT: Encoder-only, bidirectional, Masked LM / GPT: Decoder-only, autoregressive next-token prediction이 핵심 차이이다."
    },
    {
      id: 35,
      stem: "다음 중 GPT 계열 모델의 기본 학습 과제를 가장 정확히 표현한 것은?",
      options: [
        "주어진 문장에서 임의의 단어를 가리고 양쪽 문맥을 모두 보고 예측",
        "과거 토큰들과 현재까지 생성된 토큰을 바탕으로 다음 토큰의 확률 분포를 예측",
        "두 문장이 논리적으로 참인지 거짓인지 판별",
        "이미지에서 객체의 경계 상자를 예측"
      ],
      correctIndex: 1,
      explanation: "GPT는 Decoder-only 모델로, 항상 ‘다음 토큰 예측’(next token prediction)을 기본 과제로 학습한다."
    },
    {
      id: 36,
      stem: "Multi-Head Self-Attention을 사용하는 이유로 가장 적절한 것은?",
      options: [
        "하나의 Head만 쓰면 항상 과적합이 발생하기 때문이다.",
        "여러 Head가 서로 다른 관점(관계, 패턴)에 집중하게 함으로써, 단일 Head보다 더 풍부한 문맥 정보를 포착할 수 있기 때문이다.",
        "파라미터 수를 줄이기 위해서이다.",
        "Self-Attention의 계산 복잡도를 줄이기 위해서이다."
      ],
      correctIndex: 1,
      explanation: "여러 Head가 서로 다른 서브공간에서 관계를 학습해, 다양한 문맥 정보를 병렬로 포착할 수 있다."
    },
    {
      id: 37,
      stem: "Instruction tuning(지시 튜닝)에 대한 설명으로 옳은 것은?",
      options: [
        "웹 텍스트를 사용해 무작위로 다음 단어를 예측하는 사전 학습(pre-training) 단계이다.",
        "모델 파라미터 수를 줄이기 위해 일부 레이어를 제거하는 정규화 단계이다.",
        "질문–답변, 지시–응답 형식의 데이터로 추가 학습시켜, 사용자의 지시를 더 잘 따르도록 만드는 파인튜닝 단계이다.",
        "강화학습으로 보상을 최대화하는 단계이다."
      ],
      correctIndex: 2,
      explanation: "Instruction tuning은 사람이 설계한 지시/답변 데이터를 이용해, 모델이 ‘지시를 따르는 방식’으로 응답하도록 조정하는 과정이다."
    },
    {
      id: 38,
      stem: "다음 중 Encoder와 Decoder의 역할을 가장 잘 설명한 것은?",
      options: [
        "Encoder는 출력 문장을 생성하고, Decoder는 입력 문장을 인코딩한다.",
        "Encoder는 입력의 문맥을 벡터로 인코딩하고, Decoder는 이 정보를 바탕으로 출력 토큰들을 순차적으로 생성한다.",
        "Encoder와 Decoder는 항상 동일한 역할을 하며, 이름만 다르다.",
        "Encoder는 항상 이미지, Decoder는 항상 텍스트만 처리한다."
      ],
      correctIndex: 1,
      explanation: "Encoder는 입력 정보를 문맥이 반영된 표현으로 바꾸고, Decoder는 이를 기반으로 출력 시퀀스를 생성한다."
    }
  ]
}

};

let currentSetId = "set1";
let currentIndex = 0;
let score = 0;
let answeredCount = 0;

const examSelectEl = document.getElementById("exam-select");
const questionCounterEl = document.getElementById("question-counter");
const scoreInfoEl = document.getElementById("score-info");
const resetBtn = document.getElementById("reset-btn");
const questionTagEl = document.getElementById("question-tag");
const questionTitleEl = document.getElementById("question-title");
const optionsListEl = document.getElementById("options-list");
const checkBtn = document.getElementById("check-btn");
const nextBtn = document.getElementById("next-btn");
const feedbackBoxEl = document.getElementById("feedback-box");
const feedbackResultEl = document.getElementById("feedback-result");
const feedbackExplanationEl = document.getElementById("feedback-explanation");

function getCurrentSet() {
  return examSets[currentSetId];
}

function getCurrentQuestion() {
  const set = getCurrentSet();
  return set.questions[currentIndex];
}

function renderQuestion() {
  const set = getCurrentSet();
  const question = getCurrentQuestion();

  questionTagEl.textContent = `${set.tag} · Q${question.id}`;
  questionTitleEl.textContent = question.stem;
  questionCounterEl.textContent = `${currentIndex + 1} / ${set.questions.length}`;
  scoreInfoEl.textContent = `정답 ${score}개`;

  optionsListEl.innerHTML = "";
  feedbackBoxEl.classList.add("hidden");
  feedbackResultEl.textContent = "";
  feedbackExplanationEl.textContent = "";

  question.options.forEach((optText, idx) => {
    const li = document.createElement("li");
    li.className = "option-item";

    const input = document.createElement("input");
    input.type = "radio";
    input.name = "option";
    input.value = idx;

    const span = document.createElement("span");
    span.className = "option-label-text";
    span.textContent = optText;

    li.appendChild(input);
    li.appendChild(span);

    li.addEventListener("click", () => {
      const radios = optionsListEl.querySelectorAll('input[type="radio"]');
      const items = optionsListEl.querySelectorAll(".option-item");
      items.forEach((item) => item.classList.remove("selected"));
      radios.forEach((r) => (r.checked = false));

      input.checked = true;
      li.classList.add("selected");
    });

    optionsListEl.appendChild(li);
  });

  checkBtn.disabled = false;
  nextBtn.disabled = true;
}

function getSelectedOptionIndex() {
  const checked = optionsListEl.querySelector('input[type="radio"]:checked');
  if (!checked) return null;
  return parseInt(checked.value, 10);
}

function checkAnswer() {
  const selectedIdx = getSelectedOptionIndex();
  if (selectedIdx === null) {
    alert("보기 하나를 선택하세요.");
    return;
  }

  const question = getCurrentQuestion();
  const correctIdx = question.correctIndex;

  const optionItems = optionsListEl.querySelectorAll(".option-item");
  optionItems.forEach((li, idx) => {
    li.classList.remove("selected");
    if (idx === correctIdx) {
      li.classList.add("correct");
    }
  });

  if (selectedIdx === correctIdx) {
    feedbackResultEl.textContent = "정답입니다!";
    feedbackResultEl.className = "feedback-result correct";
    score += 1;
  } else {
    feedbackResultEl.textContent = "오답입니다.";
    feedbackResultEl.className = "feedback-result incorrect";
    optionItems[selectedIdx].classList.add("incorrect");
  }

  answeredCount += 1;
  scoreInfoEl.textContent = `정답 ${score}개`;
  feedbackExplanationEl.textContent = question.explanation;
  feedbackBoxEl.classList.remove("hidden");

  checkBtn.disabled = true;
  nextBtn.disabled = currentIndex >= getCurrentSet().questions.length - 1;
}

function goNextQuestion() {
  const set = getCurrentSet();
  if (currentIndex < set.questions.length - 1) {
    currentIndex += 1;
    renderQuestion();
  } else {
    alert(`마지막 문제입니다.\n\n총 ${set.questions.length}문항 중 ${score}문항 맞았습니다.`);
  }
}

function resetExam() {
  currentIndex = 0;
  score = 0;
  answeredCount = 0;
  renderQuestion();
}

examSelectEl.addEventListener("change", (e) => {
  currentSetId = e.target.value;
  resetExam();
});

checkBtn.addEventListener("click", checkAnswer);
nextBtn.addEventListener("click", goNextQuestion);
resetBtn.addEventListener("click", resetExam);

document.addEventListener("DOMContentLoaded", () => {
  resetExam();
});
